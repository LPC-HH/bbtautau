{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "import hist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import uproot\n",
    "from hist import Hist\n",
    "\n",
    "from boostedhh.hh_vars import data_key, years\n",
    "from bbtautau.postprocessing.datacardHelpers import sum_templates\n",
    "from bbtautau.postprocessing.postprocessing import shape_vars\n",
    "from bbtautau.postprocessing import plotting\n",
    "from bbtautau.postprocessing import utils as putils\n",
    "from bbtautau.postprocessing.Samples import BGS, CHANNELS\n",
    "\n",
    "from bbtautau.userConfig import MAIN_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"25July23\"\n",
    "tag = \"nobbtt\"\n",
    "bmin = 1\n",
    "use_bdt = True\n",
    "\n",
    "plot_dir = MAIN_DIR / \"plots/PostFit\" / folder / tag\n",
    "plot_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# years = [\"2022\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = uproot.open(f\"/home/users/lumori/bbtautau/src/bbtautau/cards/{folder}/{tag}/FitShapes.root\")\n",
    "templates_dir = f\"templates/{folder}/{tag}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sig_templates_dir = Path(f\"templates/25Apr23/{CHANNEL.key}\")\n",
    "# bg_templates_dir = Path(f\"templates/25Apr23/{CHANNEL.key}\")\n",
    "\n",
    "# templates_dict = {}\n",
    "# for year in years:\n",
    "#     with (sig_templates_dir / f\"{year}_templates.pkl\").open(\"rb\") as f:\n",
    "#         templates_dict[year] = pickle.load(f)\n",
    "\n",
    "# sig_pre_templates = sum_templates(templates_dict, years)\n",
    "\n",
    "# templates_dict = {}\n",
    "# for year in years:\n",
    "#     with (bg_templates_dir / f\"{year}_templates.pkl\").open(\"rb\") as f:\n",
    "#         templates_dict[year] = pickle.load(f)\n",
    "\n",
    "# bg_pre_templates = sum_templates(templates_dict, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pre_templates(templates_dir):\n",
    "    templates_dict = {}\n",
    "    for year in years:\n",
    "        with (templates_dir / f\"{year}_templates.pkl\").open(\"rb\") as f:\n",
    "            templates_dict[year] = pickle.load(f)\n",
    "\n",
    "    return sum_templates(templates_dict, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_data_key = \"data_obs\"\n",
    "\n",
    "# (name in templates, name in cards)\n",
    "hist_label_map_inverse = OrderedDict(\n",
    "    [\n",
    "        (\"qcddy\", \"CMS_bbtautau_boosted_qcd_datadriven\"),\n",
    "        (\"ttbarsl\", \"ttbarsl\"),\n",
    "        (\"ttbarll\", \"ttbarll\"),\n",
    "        (\"ttbarhad\", \"ttbarhad\"),\n",
    "        # (\"dyjets\", \"dyjets\"),\n",
    "        (\"wjets\", \"wjets\"),\n",
    "        (\"zjets\", \"zjets\"),\n",
    "        (\"hbb\", \"hbb\"),\n",
    "        (data_key, workspace_data_key),\n",
    "    ]\n",
    ")\n",
    "\n",
    "hist_label_map = {val: key for key, val in hist_label_map_inverse.items()}\n",
    "\n",
    "sig_keys = [\"bbtt\"]\n",
    "\n",
    "# pbg_keys = [bk for bk in bg_keys if bk not in [\"Diboson\", \"Hbb\", \"HWW\"]]\n",
    "pbg_keys = [\"qcddy\", \"ttbarhad\", \"ttbarsl\", \"ttbarll\", \"wjets\", \"zjets\", \"hbb\"]\n",
    "samples = pbg_keys + sig_keys + [data_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = {\n",
    "    \"prefit\": \"Pre-Fit\",\n",
    "    # \"shapes_fit_s\": \"S+B Post-Fit\",\n",
    "    \"postfit\": \"B-only Post-Fit\",\n",
    "}\n",
    "\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "\n",
    "selection_regions = {}\n",
    "for channel in CHANNELS.values():\n",
    "\n",
    "    channel = deepcopy(channel)\n",
    "    csv_dir = (\n",
    "        MAIN_DIR / f\"plots/SensitivityStudy/2025-07-19/full_presel/10July25_leptons/{channel.key}\"\n",
    "    )\n",
    "\n",
    "    # Look for any FOM-specific CSV files\n",
    "    csv_files = list(csv_dir.glob(\"*_opt_results_*.csv\"))\n",
    "\n",
    "    if len(csv_files) == 0:\n",
    "        raise ValueError(f\"No sensitivity CSV files found in {csv_dir}\")\n",
    "\n",
    "    # Take the first CSV file found and extract FOM name\n",
    "    csv_file = sorted(csv_files)[0]  # Sort for reproducible behavior\n",
    "    print(f\"Reading CSV: {csv_file}\")\n",
    "\n",
    "    # Extract FOM name from filename like \"2022_2022EE_opt_results_2sqrtB_S_var.csv\"\n",
    "    if \"_opt_results_\" in csv_file.name:\n",
    "        fom_name = csv_file.name.split(\"_opt_results_\")[1].replace(\".csv\", \"\")\n",
    "    else:\n",
    "        fom_name = \"unknown\"\n",
    "\n",
    "    # Read as simple CSV (no multi-level headers)\n",
    "    opt_results = pd.read_csv(csv_file, index_col=0)\n",
    "    print(f\"Using FOM: {fom_name}\")\n",
    "    print(f\"Available B_min values: {opt_results.columns.tolist()}\")\n",
    "\n",
    "    # Check if the target Bmin column exists\n",
    "    target_col = f\"Bmin={bmin}\"\n",
    "    if target_col not in opt_results.columns:\n",
    "        raise ValueError(\n",
    "            f\"B_min={bmin} not found in CSV. Available: {opt_results.columns.tolist()}\"\n",
    "        )\n",
    "\n",
    "    # update the CHANNEL cuts\n",
    "    channel.txbb_cut = float(opt_results.loc[\"Cut_Xbb\", target_col])\n",
    "    if use_bdt:\n",
    "        channel.txtt_BDT_cut = float(opt_results.loc[\"Cut_Xtt\", target_col])\n",
    "    else:\n",
    "        channel.txtt_cut = float(opt_results.loc[\"Cut_Xtt\", target_col])\n",
    "\n",
    "    print(\n",
    "        f\"Updated TXbb and Txtt cuts to {channel.txbb_cut} and {channel.txtt_cut if not use_bdt else channel.txtt_BDT_cut} for {channel.key}\"\n",
    "    )\n",
    "\n",
    "    selection_regions[f\"{channel.key}pass\"] = f\"{channel.label} Pass\"\n",
    "    selection_regions[f\"{channel.key}fail\"] = f\"{channel.label} Fail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = {}\n",
    "bgerrs = {}\n",
    "\n",
    "for shape in shapes:\n",
    "    print(shape)\n",
    "    hists[shape] = {\n",
    "        region: Hist(\n",
    "            hist.axis.StrCategory(samples, name=\"Sample\"),\n",
    "            *[shape_var.axis for shape_var in shape_vars],\n",
    "            storage=\"double\",\n",
    "        )\n",
    "        for region in selection_regions\n",
    "    }\n",
    "    bgerrs[shape] = {}\n",
    "\n",
    "    for region in selection_regions:\n",
    "        h = hists[shape][region]\n",
    "        templates = file[f\"{region}_{shape}\"]\n",
    "        for key, file_key in hist_label_map_inverse.items():\n",
    "            if key != data_key:\n",
    "                if file_key not in templates:\n",
    "                    print(f\"No {key} in {region}\")\n",
    "                    continue\n",
    "\n",
    "                data_key_index = np.where(np.array(list(h.axes[0])) == key)[0][0]\n",
    "                h.view(flow=False)[data_key_index, :] = templates[file_key].values()\n",
    "\n",
    "        # # if key not in fit output, take from templates\n",
    "        # for key in pbg_keys:\n",
    "        #     if key not in hist_label_map_inverse:\n",
    "        #         data_key_index = np.where(np.array(list(h.axes[0])) == key)[0][0]\n",
    "        #         h.view(flow=False)[data_key_index, :] = bg_pre_templates[region][key, ...].values()\n",
    "\n",
    "        # if key not in fit output, take from templates\n",
    "        for key in sig_keys:\n",
    "            if key not in hist_label_map_inverse:\n",
    "                sig_pre_templates = get_pre_templates(Path(f\"{templates_dir}/{region[:2]}\"))\n",
    "                data_key_index = np.where(np.array(list(h.axes[0])) == key)[0][0]\n",
    "                h.view(flow=False)[data_key_index, :] = sig_pre_templates[region[2:]][\n",
    "                    key + region[:2], ...\n",
    "                ].values()\n",
    "\n",
    "        data_key_index = np.where(np.array(list(h.axes[0])) == data_key)[0][0]\n",
    "        h.view(flow=False)[data_key_index, :] = np.nan_to_num(\n",
    "            templates[hist_label_map_inverse[data_key]].values()\n",
    "        )\n",
    "\n",
    "        bgerrs[shape][region] = np.minimum(\n",
    "            templates[\"TotalBkg\"].errors(), templates[\"TotalBkg\"].values()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not unblinded:\n",
    "#     for shapeh in hists.values():\n",
    "#         for region, h in shapeh.items():\n",
    "#             if region != \"fail\":\n",
    "#                 utils.blindBins(h, [100, 150], data_key, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ylims = {\"hhpass\": 1, \"passvbf\": 11, \"fail\": 7e5}\n",
    "sig_scale_dict = {\"bbtt\": 100}\n",
    "\n",
    "(plot_dir / \"preliminary\").mkdir(exist_ok=True, parents=True)\n",
    "(plot_dir / \"final\").mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for prelim, plabel, pplotdir in zip([True, False], [\"Preliminary\", \"\"], [\"preliminary\", \"final\"]):\n",
    "    for shape, shape_label in shapes.items():\n",
    "        # if shape != \"postfit\":\n",
    "        #     continue\n",
    "        for region, region_label in selection_regions.items():\n",
    "            pass_region = \"pass\" in region\n",
    "            for i, shape_var in enumerate(shape_vars):\n",
    "                plot_params = {\n",
    "                    \"hists\": hists[shape][region],\n",
    "                    \"sig_keys\": sig_keys,\n",
    "                    \"bg_keys\": pbg_keys,\n",
    "                    \"bg_err\": bgerrs[shape][region],\n",
    "                    \"data_err\": True,\n",
    "                    \"sig_scale_dict\": sig_scale_dict if pass_region else None,\n",
    "                    \"show\": True,\n",
    "                    \"year\": \"2022-2023\",\n",
    "                    # \"ylim\": ylims[region],\n",
    "                    # \"title\": f\"{shape_label} {region_label}\",\n",
    "                    \"region_label\": region_label,\n",
    "                    \"name\": f\"{plot_dir}/{pplotdir}/{pplotdir}_{shape}_{region}_{shape_var.var}.pdf\",\n",
    "                    \"ratio_ylims\": [0, 2],\n",
    "                    \"cmslabel\": plabel,\n",
    "                    \"leg_args\": {\"fontsize\": 22, \"ncol\": 2},\n",
    "                    \"channel\": CHANNELS[region[:2]],\n",
    "                }\n",
    "\n",
    "                plotting.ratioHistPlot(**plot_params)\n",
    "\n",
    "        # break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QCD Transfer Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "import mplhep as hep\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "hep.style.use(\"CMS\")\n",
    "formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_powerlimits((-3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylims = {\"passggf\": 1e-4, \"passvbf\": 1e-5}\n",
    "tfs = {}\n",
    "\n",
    "for region, region_label in selection_regions.items():\n",
    "\n",
    "    if region == \"fail\":\n",
    "        continue\n",
    "\n",
    "    tf = (\n",
    "        hists[\"postfit\"][region][\"qcddy\", ...] / hists[\"postfit\"][region[:2] + \"fail\"][\"qcddy\", ...]\n",
    "    )\n",
    "\n",
    "    print(tf)\n",
    "\n",
    "    tfs[region] = tf\n",
    "\n",
    "    hep.histplot(tf)\n",
    "    plt.title(f\"{region_label} Region\")\n",
    "    plt.ylabel(\"QCD Transfer Factor\")\n",
    "    plt.xlim([50, 250])\n",
    "    plt.ylim([0, 1e-4])\n",
    "    plt.ticklabel_format(style=\"sci\", axis=\"y\", scilimits=(0, 0))\n",
    "    plt.savefig(f\"{plot_dir}/{region}_QCDTF.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = tfs[\"passvbf\"]\n",
    "slope = (tf.view()[-1] - tf.view()[0]) / (245 - 55)\n",
    "yint = tf.view()[0] - slope * 55\n",
    "print(slope, yint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
