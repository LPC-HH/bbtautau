{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity study\n",
    "\n",
    "Author: Raghav Kansal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "from matplotlib import colors\n",
    "\n",
    "from boostedhh import utils, hh_vars, plotting\n",
    "from bbtautau import bbtautau_vars\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"boostedhh.utils\")\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reloads imported files on edits\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = Path(\"../../../\")\n",
    "\n",
    "plot_dir = MAIN_DIR / \"plots/SensitivityStudy/24Nov21\"\n",
    "plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "year = \"2022\"\n",
    "signal_samples_tag = \"24Nov21ParTMass_v12_private_signal\"\n",
    "data_samples_tag = \"24Nov21ParTMass_v12_private_signal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"/ceph/cms/store/user/rkansal/bbtautau/skimmer/\")\n",
    "\n",
    "samples = {\n",
    "    \"jetmet\": utils.Sample(\n",
    "        path=base_dir / data_samples_tag,\n",
    "        selector=\"JetHT|JetMET\",\n",
    "        label=\"JetMET\",\n",
    "        isData=True,\n",
    "        year=year,\n",
    "    ),\n",
    "    \"tau\": utils.Sample(\n",
    "        path=base_dir / data_samples_tag,\n",
    "        selector=\"Tau_Run\",\n",
    "        label=\"Tau\",\n",
    "        isData=True,\n",
    "        year=year,\n",
    "    ),\n",
    "    \"bbtt\": utils.Sample(\n",
    "        path=base_dir / signal_samples_tag,\n",
    "        selector=hh_vars.bbtt_sigs[\"bbtt\"],\n",
    "        label=r\"HHbb$\\tau\\tau$\",\n",
    "        isData=False,\n",
    "        year=year,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt_cut = 250\n",
    "# msd_cut = 40\n",
    "\n",
    "filters = [\n",
    "    [\n",
    "        (\"('ak8FatJetPt', '0')\", \">=\", 250),\n",
    "        (\"('ak8FatJetPNetmassLegacy', '0')\", \">=\", 50),\n",
    "        (\"('ak8FatJetPt', '1')\", \">=\", 200),\n",
    "        # (\"('ak8FatJetMsd', '0')\", \">=\", msd_cut),\n",
    "        # (\"('ak8FatJetMsd', '1')\", \">=\", msd_cut),\n",
    "        # (\"('ak8FatJetPNetXbb', '0')\", \">=\", 0.8),\n",
    "    ],\n",
    "]\n",
    "\n",
    "# save cutflow as pandas table\n",
    "# cutflow = pd.DataFrame(index=list(samples.keys()))\n",
    "\n",
    "# dictionary that will contain all information (from all samples)\n",
    "events_dict = {}\n",
    "for key, sample in samples.items():\n",
    "    events_dict[key] = utils.load_sample(sample, filters)\n",
    "\n",
    "events_dict[\"bbtthh\"] = events_dict[\"bbtt\"][events_dict[\"bbtt\"][\"GenTauhh\"][0]]\n",
    "events_dict[\"bbtthmu\"] = events_dict[\"bbtt\"][events_dict[\"bbtt\"][\"GenTauhmu\"][0]]\n",
    "events_dict[\"bbtthe\"] = events_dict[\"bbtt\"][events_dict[\"bbtt\"][\"GenTauhe\"][0]]\n",
    "del events_dict[\"bbtt\"]\n",
    "\n",
    "cutflow = pd.DataFrame(index=list(events_dict.keys()))\n",
    "utils.add_to_cutflow(events_dict, \"Preselection\", \"finalWeight\", cutflow)\n",
    "cutflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeys = [\"bbtthh\", \"bbtthmu\", \"bbtthe\"]\n",
    "\n",
    "for skey in skeys:\n",
    "    triggered = np.sum([events_dict[skey][hlt][0] for hlt in bbtautau_vars.HLT_hh], axis=0).astype(\n",
    "        bool\n",
    "    )\n",
    "    events_dict[skey] = events_dict[skey][triggered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigdict = {\"jetmet\": {}, \"tau\": {}}\n",
    "\n",
    "for key, d in trigdict.items():\n",
    "    d[\"all\"] = np.sum([events_dict[key][hlt][0] for hlt in bbtautau_vars.HLT_hh], axis=0).astype(\n",
    "        bool\n",
    "    )\n",
    "    d[\"jets\"] = np.sum([events_dict[key][hlt][0] for hlt in bbtautau_vars.HLT_jets], axis=0).astype(\n",
    "        bool\n",
    "    )\n",
    "    d[\"taus\"] = np.sum([events_dict[key][hlt][0] for hlt in bbtautau_vars.HLT_taus], axis=0).astype(\n",
    "        bool\n",
    "    )\n",
    "    d[\"jetnotau\"] = d[\"jets\"] & ~d[\"taus\"]\n",
    "    d[\"nojettau\"] = d[\"taus\"] & ~d[\"jets\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking event loss by flipping triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor = np.setdiff1d(\n",
    "    events_dict[\"jetmet\"][trigdict[\"jetmet\"][\"nojettau\"]][\"event\"][0],\n",
    "    events_dict[\"tau\"][trigdict[\"tau\"][\"nojettau\"]][\"event\"][0],\n",
    ")\n",
    "\n",
    "print(len(xor) / len(events_dict[\"jetmet\"]))\n",
    "\n",
    "xor = np.setdiff1d(\n",
    "    events_dict[\"tau\"][trigdict[\"tau\"][\"jetnotau\"]][\"event\"][0],\n",
    "    events_dict[\"jetmet\"][trigdict[\"jetmet\"][\"jets\"]][\"event\"][0],\n",
    ")\n",
    "\n",
    "print(len(xor) / len(events_dict[\"tau\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dict[\"jetmet\"] = events_dict[\"jetmet\"][trigdict[\"jetmet\"][\"jets\"]]\n",
    "events_dict[\"tau\"] = events_dict[\"tau\"][trigdict[\"tau\"][\"nojettau\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.add_to_cutflow(events_dict, \"Triggers\", \"finalWeight\", cutflow)\n",
    "cutflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taggers_dict = {}\n",
    "\n",
    "for key, events in events_dict.items():\n",
    "    tvars = {}\n",
    "\n",
    "    qcdouts = [\"QCD0HF\", \"QCD1HF\", \"QCD2HF\"]\n",
    "    topouts = [\"TopW\", \"TopbW\", \"TopbWev\", \"TopbWmv\", \"TopbWtauhv\", \"TopbWq\", \"TopbWqq\"]\n",
    "    tvars[\"PQCD\"] = sum([events[f\"ak8FatJetParT{key}\"] for key in qcdouts])\n",
    "    tvars[\"PTop\"] = sum([events[f\"ak8FatJetParT{key}\"] for key in topouts])\n",
    "\n",
    "    for disc in [\"Xbb\", \"Xtauhtauh\"]:\n",
    "        tvars[f\"{disc}vsQCD\"] = events[f\"ak8FatJetParT{disc}\"] / (\n",
    "            events[f\"ak8FatJetParT{disc}\"] + tvars[\"PQCD\"]\n",
    "        )\n",
    "        tvars[f\"{disc}vsQCDTop\"] = events[f\"ak8FatJetParT{disc}\"] / (\n",
    "            events[f\"ak8FatJetParT{disc}\"] + tvars[\"PQCD\"] + tvars[\"PTop\"]\n",
    "        )\n",
    "\n",
    "    bb_mask = tvars[\"XbbvsQCD\"][1] > tvars[\"XbbvsQCD\"][0]\n",
    "    tvars[\"bb_mask\"] = np.vstack([~bb_mask, bb_mask]).T\n",
    "    tvars[\"tautau_mask\"] = ~tvars[\"bb_mask\"]\n",
    "    taggers_dict[key] = tvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jet_vals(vals, mask):\n",
    "    return vals.values[:, :2][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "sig_key = \"bbtthh\"\n",
    "\n",
    "rocs = {}\n",
    "\n",
    "for jet in [\"bb\", \"tautau\"]:\n",
    "    rocs[jet] = {}\n",
    "    for i, disc in enumerate([\"XbbvsQCD\", \"XbbvsQCDTop\", \"XtauhtauhvsQCD\", \"XtauhtauhvsQCDTop\"]):\n",
    "        print(disc)\n",
    "        bg_scores = np.concatenate(\n",
    "            [\n",
    "                get_jet_vals(taggers_dict[key][disc], taggers_dict[key][f\"{jet}_mask\"])\n",
    "                for key in [\"jetmet\", \"tau\"]\n",
    "            ]\n",
    "        )\n",
    "        bg_weights = np.concatenate([events_dict[key][\"finalWeight\"] for key in [\"jetmet\", \"tau\"]])\n",
    "\n",
    "        sig_scores = get_jet_vals(taggers_dict[sig_key][disc], taggers_dict[sig_key][f\"{jet}_mask\"])\n",
    "        sig_weights = events_dict[sig_key][\"finalWeight\"]\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(\n",
    "            np.concatenate([np.zeros_like(bg_scores), np.ones_like(sig_scores)]),\n",
    "            np.concatenate([bg_scores, sig_scores]),\n",
    "            sample_weight=np.concatenate([bg_weights, sig_weights]),\n",
    "        )\n",
    "\n",
    "        rocs[jet][disc] = {\n",
    "            \"fpr\": fpr,\n",
    "            \"tpr\": tpr,\n",
    "            \"thresholds\": thresholds,\n",
    "            \"label\": disc,\n",
    "            \"color\": plt.cm.tab10.colors[i],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(taggers_dict[\"bbtthh\"][\"XbbvsQCD\"][0] > taggers_dict[\"bbtthh\"][\"XbbvsQCD\"][1]))\n",
    "print(\n",
    "    np.mean(\n",
    "        taggers_dict[\"bbtthh\"][\"XtauhtauhvsQCD\"][1] > taggers_dict[\"bbtthh\"][\"XtauhtauhvsQCD\"][0]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = taggers_dict[\"bbtthh\"]\n",
    "np.mean(\n",
    "    (tvars[\"XbbvsQCD\"][1] > taggers_dict[\"bbtthh\"][\"XbbvsQCD\"][0])\n",
    "    & (tvars[\"XtauhtauhvsQCD\"][0] > tvars[\"XtauhtauhvsQCD\"][1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jet, title in zip([\"bb\", \"tautau\"], [\"bb FatJet\", r\"$\\tau\\tau$ FatJet\"]):\n",
    "    plotting.multiROCCurveGrey(\n",
    "        {\"\": rocs[jet]}, title=title, show=True, plot_dir=plot_dir, name=f\"roc_{jet}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut-and-count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txbbcut = rocs[\"bb\"][\"XbbvsQCD\"][\"auc\"][plotting._find_nearest(rocs[\"bb\"][\"XbbvsQCD\"][\"tpr\"], 0.45)]\n",
    "txttcut = rocs[\"tautau\"][\"XtauhtauhvsQCD\"][\"auc\"][\n",
    "    plotting._find_nearest(rocs[\"tautau\"][\"XtauhtauhvsQCD\"][\"tpr\"], 0.25)\n",
    "]\n",
    "print(txbbcut, txttcut)\n",
    "\n",
    "sig_key = \"bbtthh\"\n",
    "bg_yield = 0\n",
    "sig_yield = 0\n",
    "\n",
    "for key in [\"bbtthh\", \"jetmet\", \"tau\"]:\n",
    "    txbbs = get_jet_vals(taggers_dict[key][\"XbbvsQCD\"], taggers_dict[key][\"bb_mask\"])\n",
    "    txtts = get_jet_vals(taggers_dict[key][\"XtauhtauhvsQCD\"], taggers_dict[key][\"tautau_mask\"])\n",
    "    massbb = get_jet_vals(events_dict[key][\"ak8FatJetPNetmassLegacy\"], taggers_dict[key][\"bb_mask\"])\n",
    "    ptbb = get_jet_vals(events_dict[key][\"ak8FatJetPt\"], taggers_dict[key][\"bb_mask\"])\n",
    "    # plt.hist(massbb, np.linspace(0, 200, 100), histtype=\"step\", label=key, weights=events_dict[key][\"finalWeight\"])\n",
    "\n",
    "    if key == sig_key:\n",
    "        cut = (txbbs > txbbcut) & (txtts > txttcut) & (massbb > 100) & (massbb < 150) & (ptbb > 250)\n",
    "        sig_yield = np.sum(events_dict[key][\"finalWeight\"][cut])\n",
    "        print(\"Sig yield\", sig_yield)\n",
    "    else:\n",
    "        cut = (txbbs > txbbcut) & (txtts > txttcut) & (ptbb > 250)\n",
    "        msb1 = (massbb > 75) & (massbb < 100)\n",
    "        msb2 = (massbb > 150) & (massbb < 175)\n",
    "        bg_yield += np.sum(events_dict[key][\"finalWeight\"][cut & msb1])\n",
    "        bg_yield += np.sum(events_dict[key][\"finalWeight\"][cut & msb2])\n",
    "\n",
    "        # bkg_yield = np.sum(events_dict[key][\"finalWeight\"][cut])\n",
    "        # print(\"Bkg yield\", bkg_yield)\n",
    "\n",
    "# plt.yscale(\"log\")\n",
    "# plt.show()\n",
    "\n",
    "print(\"BG yield\", bg_yield)\n",
    "print(\"limit\", 2 * np.sqrt(bg_yield) / sig_yield)\n",
    "print(\"limit scaled to 22-23 all channels\", 2 * np.sqrt(bg_yield) / sig_yield / np.sqrt(12))\n",
    "print(\"limit scaled to 22-24 all channels\", 2 * np.sqrt(bg_yield) / sig_yield / np.sqrt(32))\n",
    "print(\"limit scaled to Run 3 all channels\", 2 * np.sqrt(bg_yield) / sig_yield / np.sqrt(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
