{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple sensitivity study\n",
    "\n",
    "Author: Raghav Kansal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "from matplotlib import colors\n",
    "\n",
    "from boostedhh import utils, hh_vars, plotting\n",
    "from boostedhh.utils import PAD_VAL\n",
    "from bbtautau import bbtautau_vars\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"boostedhh.utils\")\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reloads imported files on edits\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = Path(\"../../../\")\n",
    "CHANNEL = \"electron\"  # options: \"hadronic\", \"electron\", \"muon\"\n",
    "\n",
    "plot_dir = MAIN_DIR / f\"plots/SensitivityStudy/25Jan22{CHANNEL}\"\n",
    "plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "year = \"2022\"\n",
    "signal_samples_tag = \"24Nov21ParTMass_v12_private_signal\"\n",
    "data_samples_tag = \"24Nov21ParTMass_v12_private_signal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"/ceph/cms/store/user/rkansal/bbtautau/skimmer/\")\n",
    "\n",
    "# define samples to load\n",
    "samples = {\n",
    "    \"jetmet\": utils.Sample(\n",
    "        path=base_dir / data_samples_tag,\n",
    "        selector=\"JetHT|JetMET\",\n",
    "        label=\"JetMET\",\n",
    "        isData=True,\n",
    "        year=year,\n",
    "    ),\n",
    "    \"tau\": utils.Sample(\n",
    "        path=base_dir / data_samples_tag,\n",
    "        selector=\"Tau_Run\",\n",
    "        label=\"Tau\",\n",
    "        isData=True,\n",
    "        year=year,\n",
    "    ),\n",
    "    \"muon\": utils.Sample(\n",
    "        path=base_dir / data_samples_tag,\n",
    "        selector=\"Muon_Run\",\n",
    "        label=\"Muon\",\n",
    "        isData=True,\n",
    "        year=year,\n",
    "    ),\n",
    "    \"egamma\": utils.Sample(\n",
    "        path=base_dir / data_samples_tag,\n",
    "        selector=\"EGamma_Run\",\n",
    "        label=\"EGamma\",\n",
    "        isData=True,\n",
    "        year=year,\n",
    "    ),\n",
    "    \"bbtt\": utils.Sample(\n",
    "        path=base_dir / signal_samples_tag,\n",
    "        selector=hh_vars.bbtt_sigs[\"bbtt\"],\n",
    "        label=r\"HHbb$\\tau\\tau$\",\n",
    "        isData=False,\n",
    "        year=year,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# pick signal key based on channel\n",
    "SIG_KEYS = {\"hadronic\": \"bbtthh\", \"electron\": \"bbtthe\", \"muon\": \"bbtthmu\"}\n",
    "SIG_KEY = SIG_KEYS[CHANNEL]\n",
    "\n",
    "# pick relevant data samples based on channel\n",
    "DATA_KEYS = {\n",
    "    \"hadronic\": [\"jetmet\", \"tau\"],\n",
    "    \"electron\": [\"jetmet\", \"tau\", \"egamma\"],\n",
    "    \"muon\": [\"jetmet\", \"tau\", \"muon\"],\n",
    "}[CHANNEL]\n",
    "\n",
    "# pick relevant lepton dataset based on channel\n",
    "LEPTON_DATASET = {\"hadronic\": None, \"electron\": \"egamma\", \"muon\": \"muon\"}[CHANNEL]\n",
    "\n",
    "LEPTON_TRIGGERS = {\n",
    "    \"hadronic\": None,\n",
    "    \"electron\": bbtautau_vars.HLT_he,\n",
    "    \"muon\": bbtautau_vars.HLT_hmu,\n",
    "}[CHANNEL]\n",
    "\n",
    "for key in [\"jetmet\", \"tau\", \"egamma\", \"muon\"]:\n",
    "    if key not in DATA_KEYS:\n",
    "        del samples[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt_cut = 250\n",
    "# msd_cut = 40\n",
    "\n",
    "filters = [\n",
    "    [\n",
    "        (\"('ak8FatJetPt', '0')\", \">=\", 250),\n",
    "        (\"('ak8FatJetPNetmassLegacy', '0')\", \">=\", 50),\n",
    "        (\"('ak8FatJetPt', '1')\", \">=\", 200),\n",
    "        # (\"('ak8FatJetMsd', '0')\", \">=\", msd_cut),\n",
    "        # (\"('ak8FatJetMsd', '1')\", \">=\", msd_cut),\n",
    "        # (\"('ak8FatJetPNetXbb', '0')\", \">=\", 0.8),\n",
    "    ],\n",
    "]\n",
    "\n",
    "# dictionary that will contain all information (from all samples)\n",
    "events_dict = {}\n",
    "for key, sample in samples.items():\n",
    "    events_dict[key] = utils.load_sample(sample, filters)\n",
    "\n",
    "events_dict[\"bbtthh\"] = events_dict[\"bbtt\"][events_dict[\"bbtt\"][\"GenTauhh\"][0]]\n",
    "events_dict[\"bbtthmu\"] = events_dict[\"bbtt\"][events_dict[\"bbtt\"][\"GenTauhmu\"][0]]\n",
    "events_dict[\"bbtthe\"] = events_dict[\"bbtt\"][events_dict[\"bbtt\"][\"GenTauhe\"][0]]\n",
    "del events_dict[\"bbtt\"]\n",
    "\n",
    "cutflow = pd.DataFrame(index=list(events_dict.keys()))\n",
    "utils.add_to_cutflow(events_dict, \"Preselection\", \"finalWeight\", cutflow)\n",
    "cutflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for skey in SIG_KEYS.values():\n",
    "    triggered = np.sum([events_dict[skey][hlt][0] for hlt in bbtautau_vars.HLT_hmu], axis=0).astype(\n",
    "        bool\n",
    "    )\n",
    "    events_dict[skey] = events_dict[skey][triggered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data (overlap removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigdict = {\"jetmet\": {}, \"tau\": {}}\n",
    "\n",
    "if LEPTON_DATASET:\n",
    "    trigdict[LEPTON_DATASET] = {}\n",
    "\n",
    "for key, d in trigdict.items():\n",
    "    d[\"all\"] = np.sum([events_dict[key][hlt][0] for hlt in bbtautau_vars.HLT_hmu], axis=0).astype(\n",
    "        bool\n",
    "    )\n",
    "    d[\"jets\"] = np.sum(\n",
    "        [\n",
    "            events_dict[key][hlt][0]\n",
    "            for hlt in bbtautau_vars.HLT_dict[\"PNet\"] + bbtautau_vars.HLT_dict[\"PFJet\"]\n",
    "        ],\n",
    "        axis=0,\n",
    "    ).astype(bool)\n",
    "    d[\"taus\"] = np.sum([events_dict[key][hlt][0] for hlt in bbtautau_vars.HLT_taus], axis=0).astype(\n",
    "        bool\n",
    "    )\n",
    "\n",
    "    d[\"taunojets\"] = ~d[\"jets\"] & d[\"taus\"]\n",
    "\n",
    "    if LEPTON_DATASET:\n",
    "        d[LEPTON_DATASET] = np.sum(\n",
    "            [events_dict[key][hlt][0] for hlt in LEPTON_TRIGGERS], axis=0\n",
    "        ).astype(bool)\n",
    "\n",
    "        d[f\"{LEPTON_DATASET}noothers\"] = ~d[\"jets\"] & ~d[\"taus\"] & d[LEPTON_DATASET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking event loss by flipping triggers (can skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xor = np.setdiff1d(\n",
    "#     events_dict[\"jetmet\"][trigdict[\"jetmet\"][\"nojettau\"]][\"event\"][0],\n",
    "#     events_dict[\"tau\"][trigdict[\"tau\"][\"nojettau\"]][\"event\"][0],\n",
    "# )\n",
    "\n",
    "# print(len(xor) / len(events_dict[\"jetmet\"]))\n",
    "\n",
    "# xor = np.setdiff1d(\n",
    "#     events_dict[\"tau\"][trigdict[\"tau\"][\"jetnotau\"]][\"event\"][0],\n",
    "#     events_dict[\"jetmet\"][trigdict[\"jetmet\"][\"jets\"]][\"event\"][0],\n",
    "# )\n",
    "\n",
    "# print(len(xor) / len(events_dict[\"tau\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply overlap removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dict[\"jetmet\"] = events_dict[\"jetmet\"][trigdict[\"jetmet\"][\"jets\"]]\n",
    "events_dict[\"tau\"] = events_dict[\"tau\"][trigdict[\"tau\"][\"taunojets\"]]\n",
    "events_dict[LEPTON_DATASET] = events_dict[LEPTON_DATASET][\n",
    "    trigdict[LEPTON_DATASET][f\"{LEPTON_DATASET}noothers\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.add_to_cutflow(events_dict, \"Triggers\", \"finalWeight\", cutflow)\n",
    "cutflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FatJet Gen Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = events_dict[SIG_KEY]\n",
    "higgs = utils.make_vector(events, \"GenHiggs\")\n",
    "bb = utils.make_vector(events, \"Genbb\")\n",
    "tt = utils.make_vector(events, \"GenTau\")\n",
    "fatjets = utils.make_vector(events, \"ak8FatJet\", mstring=\"Msd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "minbb = np.min(higgs[:, 0:1].deltaR(bb), axis=1)\n",
    "mintau = np.min(higgs[:, 0:1].deltaR(tt), axis=1)\n",
    "genhbb1 = minbb < mintau\n",
    "\n",
    "# minbb = np.min(higgs[:, 1:2].deltaR(bb), axis=1)\n",
    "# mintau = np.min(higgs[:, 1:2].deltaR(tt), axis=1)\n",
    "# genhbb2 = minbb < mintau  # overlap with genhb1 < 0.5% of the time\n",
    "\n",
    "genhbb_mask = np.vstack([genhbb1, ~genhbb1]).T\n",
    "genhbb = higgs[genhbb_mask]\n",
    "genhtt = higgs[~genhbb_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fjbbdr = fatjets.deltaR(genhbb[:, np.newaxis])\n",
    "fjidbb = np.argmin(fjbbdr, axis=1)\n",
    "fjttdr = fatjets.deltaR(genhtt[:, np.newaxis])\n",
    "fjidtt = np.argmin(fjttdr, axis=1)\n",
    "# 5% of events have overlap out of which only 5% actually have two jets both close to a gen Higgs,\n",
    "# so ignoring these overlap events for now\n",
    "overlap = fjidbb == fjidtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "taggers_dict = {}\n",
    "taukey = {\"hadronic\": \"Xtauhtauh\", \"electron\": \"Xtauhtaue\", \"muon\": \"Xtauhtaum\"}[CHANNEL]\n",
    "\n",
    "for key, events in events_dict.items():\n",
    "    tvars = {}\n",
    "\n",
    "    qcdouts = [\"QCD0HF\", \"QCD1HF\", \"QCD2HF\"]\n",
    "    topouts = [\"TopW\", \"TopbW\", \"TopbWev\", \"TopbWmv\", \"TopbWtauhv\", \"TopbWq\", \"TopbWqq\"]\n",
    "    tvars[\"PQCD\"] = sum([events[f\"ak8FatJetParT{key}\"] for key in qcdouts]).to_numpy()\n",
    "    tvars[\"PTop\"] = sum([events[f\"ak8FatJetParT{key}\"] for key in topouts]).to_numpy()\n",
    "\n",
    "    for disc in [\"Xbb\", taukey]:\n",
    "        tvars[f\"{disc}vsQCD\"] = np.nan_to_num(\n",
    "            events[f\"ak8FatJetParT{disc}\"] / (events[f\"ak8FatJetParT{disc}\"] + tvars[\"PQCD\"]),\n",
    "            nan=PAD_VAL,\n",
    "        )\n",
    "        tvars[f\"{disc}vsQCDTop\"] = np.nan_to_num(\n",
    "            events[f\"ak8FatJetParT{disc}\"]\n",
    "            / (events[f\"ak8FatJetParT{disc}\"] + tvars[\"PQCD\"] + tvars[\"PTop\"]),\n",
    "            nan=PAD_VAL,\n",
    "        )\n",
    "\n",
    "        # make sure not to choose padded jets below by accident\n",
    "        nojet3 = events[\"ak8FatJetPt\"][2] == PAD_VAL\n",
    "        tvars[f\"{disc}vsQCD\"][:, 2][nojet3] = PAD_VAL\n",
    "        tvars[f\"{disc}vsQCDTop\"][:, 2][nojet3] = PAD_VAL\n",
    "\n",
    "    tvars[\"PNetXbbvsQCD\"] = np.nan_to_num(\n",
    "        events[\"ak8FatJetPNetXbbLegacy\"]\n",
    "        / (events[\"ak8FatJetPNetXbbLegacy\"] + events[\"ak8FatJetPNetQCDLegacy\"]),\n",
    "        nan=PAD_VAL,\n",
    "    )\n",
    "\n",
    "    # jet assignment\n",
    "    fjbbpick = np.argmax(tvars[\"XbbvsQCD\"], axis=1)\n",
    "    fjttpick = np.argmax(tvars[f\"{taukey}vsQCD\"], axis=1)\n",
    "    overlap = fjbbpick == fjttpick\n",
    "    fjbbpick[overlap] = np.argsort(tvars[\"XbbvsQCD\"][overlap], axis=1)[:, -2]\n",
    "\n",
    "    # convert ids to boolean masks\n",
    "    fjbbpick_mask = np.zeros_like(tvars[\"XbbvsQCD\"], dtype=bool)\n",
    "    fjbbpick_mask[np.arange(len(fjbbpick)), fjbbpick] = True\n",
    "    fjttpick_mask = np.zeros_like(tvars[f\"{taukey}vsQCD\"], dtype=bool)\n",
    "    fjttpick_mask[np.arange(len(fjttpick)), fjttpick] = True\n",
    "\n",
    "    tvars[\"bb_mask\"] = fjbbpick_mask\n",
    "    tvars[\"tautau_mask\"] = fjttpick_mask\n",
    "    taggers_dict[key] = tvars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking bb matching accuracy (can skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = taggers_dict[SIG_KEY]\n",
    "maxtxbb = np.max(tvars[\"XbbvsQCD\"], axis=1)\n",
    "fjbbpick = np.argmax(tvars[\"XbbvsQCD\"], axis=1)\n",
    "maxtxtt = np.max(tvars[f\"{taukey}vsQCD\"], axis=1)\n",
    "fjttpick = np.argmax(tvars[f\"{taukey}vsQCD\"], axis=1)\n",
    "\n",
    "# how many are assigned correctly?\n",
    "print(np.mean(fjbbpick == fjidbb))  # 89.4%\n",
    "print(np.mean(fjttpick == fjidtt))  # 91.2%\n",
    "\n",
    "overlap = fjbbpick == fjttpick\n",
    "print(np.mean(overlap))  # 21.1%\n",
    "# how many pass reasonable tagger cuts?\n",
    "print(np.sum((maxtxbb > 0.8) * (maxtxtt > 0.95) * overlap) / np.sum(overlap))  # <0.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jet_vals(vals, mask):\n",
    "    # check if vals is a numpy array\n",
    "    if not isinstance(vals, np.ndarray):\n",
    "        vals = vals.to_numpy()\n",
    "\n",
    "    return vals[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "rocs = {}\n",
    "\n",
    "for jet in [\"bb\", \"tautau\"]:\n",
    "    print(jet)\n",
    "    rocs[jet] = {}\n",
    "    for i, disc in enumerate(\n",
    "        [\"XbbvsQCD\", \"XbbvsQCDTop\", f\"{taukey}vsQCD\", f\"{taukey}vsQCDTop\", \"PNetXbbvsQCD\"]\n",
    "    ):\n",
    "        print(\"\\t\" + disc)\n",
    "        bg_scores = np.concatenate(\n",
    "            [\n",
    "                get_jet_vals(taggers_dict[key][disc], taggers_dict[key][f\"{jet}_mask\"])\n",
    "                for key in DATA_KEYS\n",
    "            ]\n",
    "        )\n",
    "        bg_weights = np.concatenate([events_dict[key][\"finalWeight\"] for key in DATA_KEYS])\n",
    "\n",
    "        sig_scores = get_jet_vals(taggers_dict[SIG_KEY][disc], taggers_dict[SIG_KEY][f\"{jet}_mask\"])\n",
    "        sig_weights = events_dict[SIG_KEY][\"finalWeight\"]\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(\n",
    "            np.concatenate([np.zeros_like(bg_scores), np.ones_like(sig_scores)]),\n",
    "            np.concatenate([bg_scores, sig_scores]),\n",
    "            sample_weight=np.concatenate([bg_weights, sig_weights]),\n",
    "        )\n",
    "\n",
    "        rocs[jet][disc] = {\n",
    "            \"fpr\": fpr,\n",
    "            \"tpr\": tpr,\n",
    "            \"thresholds\": thresholds,\n",
    "            \"label\": disc,\n",
    "            \"color\": plt.cm.tab10.colors[i],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jet, title in zip([\"bb\", \"tautau\"], [\"bb FatJet\", rf\"$\\tau_h\\tau_{CHANNEL[0]}$ FatJet\"]):\n",
    "    plotting.multiROCCurveGrey(\n",
    "        {\"\": rocs[jet]}, title=title, show=True, plot_dir=plot_dir, name=f\"roc_{jet}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, label in zip([\"hhbbtt\", \"data\"], [\"HHbbtt\", \"Data\"]):\n",
    "    if key == \"hhbbtt\":\n",
    "        events = events_dict[SIG_KEY]\n",
    "    else:\n",
    "        events = pd.concat([events_dict[dkey] for dkey in DATA_KEYS])\n",
    "\n",
    "    bins = np.linspace(0, 250, 50)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(24, 10))\n",
    "\n",
    "    for i, (jet, jlabel) in enumerate(zip([\"bb\", \"tautau\"], [\"bb FatJet\", r\"$\\tau\\tau$ FatJet\"])):\n",
    "        ax = axs[i]\n",
    "        if key == \"hhbbtt\":\n",
    "            mask = taggers_dict[SIG_KEY][f\"{jet}_mask\"]\n",
    "        else:\n",
    "            mask = np.concatenate([taggers_dict[dkey][f\"{jet}_mask\"] for dkey in DATA_KEYS], axis=0)\n",
    "\n",
    "        for j, (mkey, mlabel) in enumerate(\n",
    "            zip(\n",
    "                [\n",
    "                    \"ak8FatJetMsd\",\n",
    "                    \"ak8FatJetPNetmassLegacy\",\n",
    "                    \"ak8FatJetParTmassResApplied\",\n",
    "                    \"ak8FatJetParTmassVisApplied\",\n",
    "                ],\n",
    "                [\"SoftDrop\", \"PNetLegacy\", \"ParT Res\", \"ParT Vis\"],\n",
    "            )\n",
    "        ):\n",
    "            ax.hist(\n",
    "                get_jet_vals(events[mkey], mask),\n",
    "                bins=bins,\n",
    "                histtype=\"step\",\n",
    "                weights=events[\"finalWeight\"],\n",
    "                label=mlabel,\n",
    "                linewidth=2,\n",
    "                color=plt.cm.tab10.colors[j],\n",
    "            )\n",
    "\n",
    "        ax.vlines(125, 0, ax.get_ylim()[1], linestyle=\"--\", color=\"k\", alpha=0.1)\n",
    "        ax.set_title(jlabel, fontsize=24)\n",
    "        ax.set_xlabel(\"Mass [GeV]\")\n",
    "        # rax.set_xlabel(\"Mass [GeV]\")\n",
    "        ax.set_ylabel(\"Events\")\n",
    "        ax.legend()\n",
    "        ax.set_ylim(0)\n",
    "        hep.cms.label(\n",
    "            ax=ax,\n",
    "            data=key == \"data\",\n",
    "            year=2022,\n",
    "            com=\"13.6\",\n",
    "            fontsize=20,\n",
    "            lumi=f\"{hh_vars.LUMI[year] / 1000:.1f}\",\n",
    "        )\n",
    "\n",
    "    plt.savefig(plot_dir / f\"{key}_mass.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut-and-count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbeff, tteff = 0.44, 0.36\n",
    "mbb1, mbb2 = 110.0, 160.0\n",
    "mbbw2 = (mbb2 - mbb1) / 2\n",
    "mtt1, mtt2 = 50, 1500\n",
    "\n",
    "# mbbk = \"PNetmassLegacy\"\n",
    "mbbk = \"ParTmassResApplied\"\n",
    "# mttk = \"PNetmassLegacy\"\n",
    "mttk = \"ParTmassResApplied\"\n",
    "\n",
    "txbbcut = rocs[\"bb\"][\"XbbvsQCD\"][\"thresholds\"][\n",
    "    plotting._find_nearest(rocs[\"bb\"][\"XbbvsQCD\"][\"tpr\"], bbeff)\n",
    "]\n",
    "txttcut = rocs[\"tautau\"][f\"{taukey}vsQCDTop\"][\"thresholds\"][\n",
    "    plotting._find_nearest(rocs[\"tautau\"][f\"{taukey}vsQCDTop\"][\"tpr\"], tteff)\n",
    "]\n",
    "print(\"TXbb cut, TXtt cut:\", txbbcut, txttcut)\n",
    "\n",
    "bg_yield = 0\n",
    "sig_yield = 0\n",
    "\n",
    "for key in [SIG_KEY] + DATA_KEYS:\n",
    "    txbbs = get_jet_vals(taggers_dict[key][\"XbbvsQCD\"], taggers_dict[key][\"bb_mask\"])\n",
    "    txtts = get_jet_vals(taggers_dict[key][f\"{taukey}vsQCDTop\"], taggers_dict[key][\"tautau_mask\"])\n",
    "    masstt = get_jet_vals(events_dict[key][f\"ak8FatJet{mttk}\"], taggers_dict[key][\"tautau_mask\"])\n",
    "    massbb = get_jet_vals(events_dict[key][f\"ak8FatJet{mbbk}\"], taggers_dict[key][\"bb_mask\"])\n",
    "    ptbb = get_jet_vals(events_dict[key][\"ak8FatJetPt\"], taggers_dict[key][\"bb_mask\"])\n",
    "    # plt.hist(massbb, np.linspace(0, 200, 100), histtype=\"step\", label=key, weights=events_dict[key][\"finalWeight\"])\n",
    "\n",
    "    if key == SIG_KEY:\n",
    "        cut = (\n",
    "            (txbbs > txbbcut)\n",
    "            & (txtts > txttcut)\n",
    "            & (masstt > mtt1)\n",
    "            & (masstt < mtt2)\n",
    "            & (massbb > mbb1)\n",
    "            & (massbb < mbb2)\n",
    "            & (ptbb > 250)\n",
    "        )\n",
    "        sig_yield = np.sum(events_dict[key][\"finalWeight\"][cut])\n",
    "        print(\"Sig yield\", sig_yield)\n",
    "    else:\n",
    "        cut = (\n",
    "            (txbbs > txbbcut) & (txtts > txttcut) & (masstt > mtt1) & (masstt < mtt2) & (ptbb > 250)\n",
    "        )\n",
    "        msb1 = (massbb > (mbb1 - mbbw2)) & (massbb < mbb1)\n",
    "        msb2 = (massbb > mbb2) & (massbb < (mbb2 + mbbw2))\n",
    "        bg_yield += np.sum(events_dict[key][\"finalWeight\"][cut & msb1])\n",
    "        bg_yield += np.sum(events_dict[key][\"finalWeight\"][cut & msb2])\n",
    "\n",
    "        # bkg_yield = np.sum(events_dict[key][\"finalWeight\"][cut])\n",
    "        # print(\"Bkg yield\", bkg_yield)\n",
    "\n",
    "# plt.yscale(\"log\")\n",
    "# plt.show()\n",
    "\n",
    "print(\"BG yield\", bg_yield)\n",
    "print(\"limit\", 2 * np.sqrt(bg_yield) / sig_yield)\n",
    "print(\n",
    "    \"limit scaled to 22-23 all channels\",\n",
    "    2 * np.sqrt(bg_yield) / sig_yield / np.sqrt(hh_vars.LUMI[\"2022-2023\"] / hh_vars.LUMI[year] * 3),\n",
    ")\n",
    "print(\n",
    "    \"limit scaled to 22-24 all channels\",\n",
    "    2\n",
    "    * np.sqrt(bg_yield)\n",
    "    / sig_yield\n",
    "    / np.sqrt((124000 + hh_vars.LUMI[\"2022-2023\"]) / hh_vars.LUMI[year] * 3),\n",
    ")\n",
    "print(\n",
    "    \"limit scaled to Run 3 all channels\",\n",
    "    2 * np.sqrt(bg_yield) / sig_yield / np.sqrt((360000) / hh_vars.LUMI[year] * 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
