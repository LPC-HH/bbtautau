{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "from matplotlib import colors\n",
    "\n",
    "from boostedhh import utils, hh_vars, plotting\n",
    "from boostedhh.utils import PAD_VAL\n",
    "from bbtautau import bbtautau_vars\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"boostedhh.utils\")\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reloads imported files on edits\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = Path(\"../../../\")\n",
    "CHANNEL = \"muon\"  # options: \"hadronic\", \"electron\", \"muon\"\n",
    "\n",
    "base_dir = Path(\"/ceph/cms/store/user/rkansal/bbtautau/skimmer/\")\n",
    "\n",
    "plot_dir = MAIN_DIR / f\"plots/SensitivityStudy/25Jan22{CHANNEL}\"\n",
    "plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "years = [\"2022\", \"2022EE\"]\n",
    "\n",
    "tags = {\n",
    "    \"data\": {\n",
    "        \"2022\": \"24Nov21ParTMass_v12_private_signal\",\n",
    "        \"2022EE\": \"25Jan22AddYears_v12_private_signal\",\n",
    "    },\n",
    "    \"signal\": {\n",
    "        \"2022\": \"24Nov21ParTMass_v12_private_signal\",\n",
    "        \"2022EE\": \"25Jan22AddYears_v12_private_signal\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcdouts = [\"QCD0HF\", \"QCD1HF\", \"QCD2HF\"]\n",
    "topouts = [\"TopW\", \"TopbW\", \"TopbWev\", \"TopbWmv\", \"TopbWtauhv\", \"TopbWq\", \"TopbWqq\"]\n",
    "sigouts = [\"Xtauhtauh\", \"Xtauhtaue\", \"Xtauhtaum\", \"Xbb\"]\n",
    "\n",
    "columns_data = [\n",
    "    (\"weight\", 1),\n",
    "    (\"ak8FatJetMsd\", 3),\n",
    "    (\"ak8FatJetEta\", 3),\n",
    "    (\"ak8FatJetPt\", 3),\n",
    "    (\"ak8FatJetPhi\", 3),\n",
    "    (\"ak8FatJetPNetXbbLegacy\", 3),\n",
    "    (\"ak8FatJetPNetQCDLegacy\", 3),\n",
    "    (\"ak8FatJetPNetmassLegacy\", 3),\n",
    "    (\"ak8FatJetParTmassResApplied\", 3),\n",
    "    (\"ak8FatJetParTmassVisApplied\", 3),\n",
    "]\n",
    "\n",
    "for branch in (\n",
    "    bbtautau_vars.HLT_hmu[years[0]]\n",
    "    + bbtautau_vars.HLT_he[years[0]]\n",
    "    + bbtautau_vars.HLT_dict[years[0]][\"PNet\"]\n",
    "    + bbtautau_vars.HLT_dict[years[0]][\"PFJet\"]\n",
    "    + bbtautau_vars.HLT_taus[years[0]]\n",
    "):\n",
    "    columns_data.append((branch, 1))\n",
    "\n",
    "for branch in [f\"ak8FatJetParT{key}\" for key in qcdouts + topouts + sigouts]:\n",
    "    columns_data.append((branch, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbtautau_vars.HLT_hmu[years[0]] + bbtautau_vars.HLT_he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "columns_signal = copy.deepcopy(columns_data) + [\n",
    "    (\"GenTauhh\", 1),\n",
    "    (\"GenTauhmu\", 1),\n",
    "    (\"GenTauhe\", 1),\n",
    "    (\"GenHiggsEta\", 2),\n",
    "    (\"GenHiggsPt\", 2),\n",
    "    (\"GenHiggsPhi\", 2),\n",
    "    (\"GenHiggsMass\", 2),\n",
    "    (\"GenbbEta\", 2),\n",
    "    (\"GenbbPt\", 2),\n",
    "    (\"GenbbPhi\", 2),\n",
    "    (\"GenbbMass\", 2),\n",
    "    (\"GenTauEta\", 2),\n",
    "    (\"GenTauPt\", 2),\n",
    "    (\"GenTauPhi\", 2),\n",
    "    (\"GenTauMass\", 2),\n",
    "    (\"single_weight_genweight\", 1),\n",
    "    (\"single_weight_pileup\", 1),\n",
    "    (\"single_weight_ISRPartonShower\", 1),\n",
    "    (\"single_weight_FSRPartonShower\", 1),\n",
    "]\n",
    "# columns_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year = \"2022\"\n",
    "# a = utils.Sample(\n",
    "#             path=base_dir / tags[\"signal\"][year],\n",
    "#             selector=hh_vars.bbtt_sigs[\"bbtt\"][year],\n",
    "#             label=r\"HHbb$\\tau\\tau$\",\n",
    "#             isData=False,\n",
    "#             year=year,\n",
    "#             load_columns = utils.format_columns(columns_signal),\n",
    "#         )\n",
    "# b = utils.load_sample(a )\n",
    "# b[\"ak8FatJetPt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define samples to load\n",
    "samples = {\n",
    "    year: {\n",
    "        \"jetmet\": utils.Sample(\n",
    "            path=base_dir / tags[\"data\"][year],\n",
    "            selector=\"JetHT|JetMET\",\n",
    "            label=\"JetMET\",\n",
    "            isData=True,\n",
    "            year=year,\n",
    "            load_columns=utils.format_columns(columns_data),\n",
    "        ),\n",
    "        \"tau\": utils.Sample(\n",
    "            path=base_dir / tags[\"data\"][year],\n",
    "            selector=\"Tau_Run\",\n",
    "            label=\"Tau\",\n",
    "            isData=True,\n",
    "            year=year,\n",
    "            load_columns=utils.format_columns(columns_data),\n",
    "        ),\n",
    "        \"muon\": utils.Sample(\n",
    "            path=base_dir / tags[\"data\"][year],\n",
    "            selector=\"Muon_Run\",\n",
    "            label=\"Muon\",\n",
    "            isData=True,\n",
    "            year=year,\n",
    "            load_columns=utils.format_columns(columns_data),\n",
    "        ),\n",
    "        \"egamma\": utils.Sample(\n",
    "            path=base_dir / tags[\"data\"][year],\n",
    "            selector=\"EGamma_Run\",\n",
    "            label=\"EGamma\",\n",
    "            isData=True,\n",
    "            year=year,\n",
    "            load_columns=utils.format_columns(columns_data),\n",
    "        ),\n",
    "        \"bbtt\": utils.Sample(\n",
    "            path=base_dir / tags[\"signal\"][year],\n",
    "            selector=hh_vars.bbtt_sigs[\"bbtt\"][year],\n",
    "            label=r\"HHbb$\\tau\\tau$\",\n",
    "            isData=False,\n",
    "            year=year,\n",
    "            load_columns=utils.format_columns(columns_signal),\n",
    "        ),\n",
    "    }\n",
    "    for year in years\n",
    "}\n",
    "\n",
    "# pick signal key based on channel\n",
    "SIG_KEYS = {\"hadronic\": \"bbtthh\", \"electron\": \"bbtthe\", \"muon\": \"bbtthmu\"}\n",
    "SIG_KEY = SIG_KEYS[CHANNEL]\n",
    "\n",
    "# pick relevant data samples based on channel\n",
    "DATA_KEYS = {\n",
    "    \"hadronic\": [\"jetmet\", \"tau\"],\n",
    "    \"electron\": [\"jetmet\", \"tau\", \"egamma\"],\n",
    "    \"muon\": [\"jetmet\", \"tau\", \"muon\"],\n",
    "}[CHANNEL]\n",
    "\n",
    "# pick relevant lepton dataset based on channel\n",
    "LEPTON_DATASET = {\"hadronic\": None, \"electron\": \"egamma\", \"muon\": \"muon\"}[CHANNEL]\n",
    "\n",
    "LEPTON_TRIGGERS = {\n",
    "    \"hadronic\": None,\n",
    "    \"electron\": bbtautau_vars.HLT_he,\n",
    "    \"muon\": bbtautau_vars.HLT_hmu,\n",
    "}[CHANNEL]\n",
    "\n",
    "for key in [\"jetmet\", \"tau\", \"egamma\", \"muon\"]:\n",
    "    if key not in DATA_KEYS:\n",
    "        for year in years:\n",
    "            del samples[year][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt_cut = 250\n",
    "# msd_cut = 40\n",
    "\n",
    "filters = [\n",
    "    [\n",
    "        (\"('ak8FatJetPt', '0')\", \">=\", 250),\n",
    "        (\"('ak8FatJetPNetmassLegacy', '0')\", \">=\", 50),\n",
    "        (\"('ak8FatJetPt', '1')\", \">=\", 200),\n",
    "        # (\"('ak8FatJetMsd', '0')\", \">=\", msd_cut),\n",
    "        # (\"('ak8FatJetMsd', '1')\", \">=\", msd_cut),\n",
    "        # (\"('ak8FatJetPNetXbb', '0')\", \">=\", 0.8),\n",
    "    ],\n",
    "]\n",
    "\n",
    "\n",
    "# dictionary that will contain all information (from all samples)\n",
    "events_dict = {year: {} for year in years}\n",
    "\n",
    "for year in years:\n",
    "    for key, sample in samples[year].items():\n",
    "        events_dict[year][key] = utils.load_sample(sample, filters)\n",
    "\n",
    "    events_dict[year][\"bbtthh\"] = events_dict[year][\"bbtt\"][\n",
    "        events_dict[year][\"bbtt\"][\"GenTauhh\"][0]\n",
    "    ]\n",
    "    events_dict[year][\"bbtthmu\"] = events_dict[year][\"bbtt\"][\n",
    "        events_dict[year][\"bbtt\"][\"GenTauhmu\"][0]\n",
    "    ]\n",
    "    events_dict[year][\"bbtthe\"] = events_dict[year][\"bbtt\"][\n",
    "        events_dict[year][\"bbtt\"][\"GenTauhe\"][0]\n",
    "    ]\n",
    "    del events_dict[year][\"bbtt\"]\n",
    "\n",
    "\n",
    "cutflow = {year: pd.DataFrame(index=list(events_dict[year].keys())) for year in years}\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    utils.add_to_cutflow(events_dict[year], \"Preselection\", \"finalWeight\", cutflow[year])\n",
    "\n",
    "# cutflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    for skey in SIG_KEYS.values():\n",
    "        triggered = np.sum(\n",
    "            [events_dict[year][skey][hlt].iloc[:, 0] for hlt in bbtautau_vars.HLT_hmu], axis=0\n",
    "        ).astype(bool)\n",
    "\n",
    "        events_dict[year][skey] = events_dict[year][skey][triggered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data (overlap removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigdict = {year: {\"jetmet\": {}, \"tau\": {}} for year in years}\n",
    "\n",
    "if LEPTON_DATASET:\n",
    "    for year in years:\n",
    "        trigdict[year][LEPTON_DATASET] = {}\n",
    "\n",
    "for year in years:\n",
    "    for key, d in trigdict[year].items():\n",
    "        d[\"all\"] = np.sum(\n",
    "            [events_dict[year][key][hlt].iloc[:, 0] for hlt in bbtautau_vars.HLT_hmu], axis=0\n",
    "        ).astype(bool)\n",
    "        d[\"jets\"] = np.sum(\n",
    "            [\n",
    "                events_dict[year][key][hlt].iloc[:, 0]\n",
    "                for hlt in bbtautau_vars.HLT_dict[\"PNet\"] + bbtautau_vars.HLT_dict[\"PFJet\"]\n",
    "            ],\n",
    "            axis=0,\n",
    "        ).astype(bool)\n",
    "        d[\"taus\"] = np.sum(\n",
    "            [events_dict[year][key][hlt].iloc[:, 0] for hlt in bbtautau_vars.HLT_taus], axis=0\n",
    "        ).astype(bool)\n",
    "\n",
    "        d[\"taunojets\"] = ~d[\"jets\"] & d[\"taus\"]\n",
    "\n",
    "        if LEPTON_DATASET:\n",
    "            d[LEPTON_DATASET] = np.sum(\n",
    "                [events_dict[year][key][hlt].iloc[:, 0] for hlt in LEPTON_TRIGGERS], axis=0\n",
    "            ).astype(bool)\n",
    "\n",
    "            d[f\"{LEPTON_DATASET}noothers\"] = ~d[\"jets\"] & ~d[\"taus\"] & d[LEPTON_DATASET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking event loss by flipping triggers (can skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xor = np.setdiff1d(\n",
    "#     events_dict[\"jetmet\"][trigdict[\"jetmet\"][\"nojettau\"]][\"event\"][0],\n",
    "#     events_dict[\"tau\"][trigdict[\"tau\"][\"nojettau\"]][\"event\"][0],\n",
    "# )\n",
    "\n",
    "# print(len(xor) / len(events_dict[\"jetmet\"]))\n",
    "\n",
    "# xor = np.setdiff1d(\n",
    "#     events_dict[\"tau\"][trigdict[\"tau\"][\"jetnotau\"]][\"event\"][0],\n",
    "#     events_dict[\"jetmet\"][trigdict[\"jetmet\"][\"jets\"]][\"event\"][0],\n",
    "# )\n",
    "\n",
    "# print(len(xor) / len(events_dict[\"tau\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply overlap removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    events_dict[year][\"jetmet\"] = events_dict[year][\"jetmet\"][trigdict[year][\"jetmet\"][\"jets\"]]\n",
    "    events_dict[year][\"tau\"] = events_dict[year][\"tau\"][trigdict[year][\"tau\"][\"taunojets\"]]\n",
    "    if LEPTON_DATASET:\n",
    "        events_dict[year][LEPTON_DATASET] = events_dict[year][LEPTON_DATASET][\n",
    "            trigdict[year][LEPTON_DATASET][f\"{LEPTON_DATASET}noothers\"]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    utils.add_to_cutflow(events_dict[year], \"Triggers\", \"finalWeight\", cutflow[year])\n",
    "cutflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FatJet Gen Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge years in gen matching\n",
    "events = pd.concat([events_dict[y][SIG_KEY] for y in years], keys=[y for y in years])\n",
    "\n",
    "higgs = utils.make_vector(events, \"GenHiggs\")\n",
    "bb = utils.make_vector(events, \"Genbb\")\n",
    "tt = utils.make_vector(events, \"GenTau\")\n",
    "fatjets = utils.make_vector(events, \"ak8FatJet\", mstring=\"Msd\")\n",
    "\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minbb = np.min(higgs[:, 0:1].deltaR(bb), axis=1)\n",
    "mintau = np.min(higgs[:, 0:1].deltaR(tt), axis=1)\n",
    "genhbb1 = minbb < mintau\n",
    "\n",
    "# minbb = np.min(higgs[:, 1:2].deltaR(bb), axis=1)\n",
    "# mintau = np.min(higgs[:, 1:2].deltaR(tt), axis=1)\n",
    "# genhbb2 = minbb < mintau  # overlap with genhb1 < 0.5% of the time\n",
    "\n",
    "genhbb_mask = np.vstack([genhbb1, ~genhbb1]).T\n",
    "genhbb = higgs[genhbb_mask]\n",
    "genhtt = higgs[~genhbb_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fjbbdr = fatjets.deltaR(genhbb[:, np.newaxis])\n",
    "fjidbb = np.argmin(fjbbdr, axis=1)\n",
    "fjttdr = fatjets.deltaR(genhtt[:, np.newaxis])\n",
    "fjidtt = np.argmin(fjttdr, axis=1)\n",
    "# 5% of events have overlap out of which only 5% actually have two jets both close to a gen Higgs,\n",
    "# so ignoring these overlap events for now\n",
    "overlap = fjidbb == fjidtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taggers_dict = {year: {} for year in years}\n",
    "\n",
    "taukey = {\"hadronic\": \"Xtauhtauh\", \"electron\": \"Xtauhtaue\", \"muon\": \"Xtauhtaum\"}[CHANNEL]\n",
    "\n",
    "for year in years:\n",
    "    for key, events in events_dict[year].items():\n",
    "        tvars = {}\n",
    "\n",
    "        qcdouts = [\"QCD0HF\", \"QCD1HF\", \"QCD2HF\"]  # HF = heavy flavor = {c,b}\n",
    "        topouts = [\"TopW\", \"TopbW\"]  # \"TopbWev\", \"TopbWmv\", \"TopbWtauhv\", \"TopbWq\", \"TopbWqq\"]\n",
    "        tvars[\"PQCD\"] = sum([events[f\"ak8FatJetParT{k}\"] for k in qcdouts]).to_numpy()\n",
    "        tvars[\"PTop\"] = sum([events[f\"ak8FatJetParT{k}\"] for k in topouts]).to_numpy()\n",
    "\n",
    "        for disc in [\"Xbb\", taukey]:\n",
    "            tvars[f\"{disc}vsQCD\"] = np.nan_to_num(\n",
    "                events[f\"ak8FatJetParT{disc}\"] / (events[f\"ak8FatJetParT{disc}\"] + tvars[\"PQCD\"]),\n",
    "                nan=PAD_VAL,\n",
    "            )\n",
    "            tvars[f\"{disc}vsQCDTop\"] = np.nan_to_num(\n",
    "                events[f\"ak8FatJetParT{disc}\"]\n",
    "                / (events[f\"ak8FatJetParT{disc}\"] + tvars[\"PQCD\"] + tvars[\"PTop\"]),\n",
    "                nan=PAD_VAL,\n",
    "            )\n",
    "\n",
    "            # make sure not to choose padded jets below by accident\n",
    "            nojet3 = events[\"ak8FatJetPt\"][2] == PAD_VAL\n",
    "            tvars[f\"{disc}vsQCD\"][:, 2][nojet3] = PAD_VAL\n",
    "            tvars[f\"{disc}vsQCDTop\"][:, 2][nojet3] = PAD_VAL\n",
    "\n",
    "        tvars[\"PNetXbbvsQCD\"] = np.nan_to_num(\n",
    "            events[\"ak8FatJetPNetXbbLegacy\"]\n",
    "            / (events[\"ak8FatJetPNetXbbLegacy\"] + events[\"ak8FatJetPNetQCDLegacy\"]),\n",
    "            nan=PAD_VAL,\n",
    "        )\n",
    "\n",
    "        # jet assignment\n",
    "        fjbbpick = np.argmax(tvars[\"XbbvsQCD\"], axis=1)\n",
    "        fjttpick = np.argmax(tvars[f\"{taukey}vsQCD\"], axis=1)\n",
    "        overlap = fjbbpick == fjttpick\n",
    "        fjbbpick[overlap] = np.argsort(tvars[\"XbbvsQCD\"][overlap], axis=1)[:, -2]\n",
    "\n",
    "        # convert ids to boolean masks\n",
    "        fjbbpick_mask = np.zeros_like(tvars[\"XbbvsQCD\"], dtype=bool)\n",
    "        fjbbpick_mask[np.arange(len(fjbbpick)), fjbbpick] = True\n",
    "        fjttpick_mask = np.zeros_like(tvars[f\"{taukey}vsQCD\"], dtype=bool)\n",
    "        fjttpick_mask[np.arange(len(fjttpick)),] = True\n",
    "\n",
    "        tvars[\"bb_mask\"] = fjbbpick_mask\n",
    "        tvars[\"tautau_mask\"] = fjttpick_mask\n",
    "        taggers_dict[year][key] = tvars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking bb matching accuracy (can skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = {}\n",
    "if len(years) > 1:\n",
    "    for key in taggers_dict[years[0]][SIG_KEY].keys():\n",
    "        tvars[key] = np.concatenate([taggers_dict[year][SIG_KEY][key] for year in years])\n",
    "else:\n",
    "    tvars = taggers_dict[years[0]][SIG_KEY]\n",
    "\n",
    "maxtxbb = np.max(tvars[\"XbbvsQCD\"], axis=1)\n",
    "fjbbpick = np.argmax(tvars[\"XbbvsQCD\"], axis=1)\n",
    "maxtxtt = np.max(tvars[f\"{taukey}vsQCD\"], axis=1)\n",
    "fjttpick = np.argmax(tvars[f\"{taukey}vsQCD\"], axis=1)\n",
    "\n",
    "# how many are assigned correctly?\n",
    "print(np.mean(fjbbpick == fjidbb))  # 89.4%\n",
    "print(np.mean(fjttpick == fjidtt))  # 91.2%\n",
    "\n",
    "overlap = fjbbpick == fjttpick\n",
    "print(np.mean(overlap))  # 21.1%\n",
    "# how many pass reasonable tagger cuts?\n",
    "print(np.sum((maxtxbb > 0.8) * (maxtxtt > 0.95) * overlap) / np.sum(overlap))  # <0.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jet_vals(vals, mask):\n",
    "    # check if vals is a numpy array\n",
    "    if not isinstance(vals, np.ndarray):\n",
    "        vals = vals.to_numpy()\n",
    "\n",
    "    return vals[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(taggers_dict[years[0]])\n",
    "for key in taggers_dict[years[0]]:\n",
    "    print(\"1 \\n\\n\\n\")\n",
    "    print([taggers_dict[year][key] for year in years])\n",
    "    # np.concatenate([taggers_dict[year][key] for year in years])\n",
    "# taggers_dict_merged  = {key: np.concatenate([taggers_dict[year][key] for year in years]) for key in taggers_dict[years[0]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "def compute_rocs(\n",
    "    years,\n",
    "    jets=[\"bb\", \"tautau\"],\n",
    "    discs=[\"XbbvsQCD\", \"XbbvsQCDTop\", f\"{taukey}vsQCD\", f\"{taukey}vsQCDTop\", \"PNetXbbvsQCD\"],\n",
    "):\n",
    "\n",
    "    rocs = {}\n",
    "\n",
    "    if len(years) > 1:  # needs some work\n",
    "        taggers_dict_merged = {\n",
    "            key: np.concatenate([taggers_dict[year][key] for year in years])\n",
    "            for key in taggers_dict[years[0]]\n",
    "        }\n",
    "        events_dict_merged = {\n",
    "            key: np.concatenate([events_dict[year][key] for year in years])\n",
    "            for key in events_dict[years[0]]\n",
    "        }\n",
    "    else:\n",
    "        taggers_dict_merged = taggers_dict[years[0]]\n",
    "        events_dict_merged = events_dict[years[0]]\n",
    "\n",
    "    for jet in jets:\n",
    "        print(jet)\n",
    "        rocs[jet] = {}\n",
    "        for i, disc in enumerate(discs):\n",
    "            print(\"\\t\" + disc)\n",
    "\n",
    "            bg_scores = np.concatenate(\n",
    "                [\n",
    "                    get_jet_vals(\n",
    "                        taggers_dict_merged[key][disc], taggers_dict_merged[key][f\"{jet}_mask\"]\n",
    "                    )\n",
    "                    for key in DATA_KEYS\n",
    "                ]\n",
    "            )\n",
    "            bg_weights = np.concatenate(\n",
    "                [events_dict_merged[key][\"finalWeight\"] for key in DATA_KEYS]\n",
    "            )\n",
    "\n",
    "            sig_scores = get_jet_vals(\n",
    "                taggers_dict_merged[SIG_KEY][disc], taggers_dict_merged[SIG_KEY][f\"{jet}_mask\"]\n",
    "            )\n",
    "            sig_weights = events_dict_merged[SIG_KEY][\"finalWeight\"]\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(\n",
    "                np.concatenate([np.zeros_like(bg_scores), np.ones_like(sig_scores)]),\n",
    "                np.concatenate([bg_scores, sig_scores]),\n",
    "                sample_weight=np.concatenate([bg_weights, sig_weights]),\n",
    "            )\n",
    "\n",
    "            rocs[jet][disc] = {\n",
    "                \"fpr\": fpr,\n",
    "                \"tpr\": tpr,\n",
    "                \"thresholds\": thresholds,\n",
    "                \"label\": disc,\n",
    "                \"color\": plt.cm.tab10.colors[i],\n",
    "            }\n",
    "\n",
    "    return rocs\n",
    "\n",
    "\n",
    "rocs = {year: compute_rocs([year]) for year in years}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    for jet, title in zip([\"bb\", \"tautau\"], [\"bb FatJet\", rf\"$\\tau_h\\tau_{CHANNEL[0]}$ FatJet\"]):\n",
    "        plotting.multiROCCurveGrey(\n",
    "            {\"\": rocs[year][jet]},\n",
    "            title=title + \" \" + year,\n",
    "            show=True,\n",
    "            plot_dir=plot_dir,\n",
    "            name=f\"roc_{jet} {year}\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    for key, label in zip([\"hhbbtt\", \"data\"], [\"HHbbtt\", \"Data\"]):\n",
    "        if key == \"hhbbtt\":\n",
    "            events = events_dict[year][SIG_KEY]\n",
    "        else:\n",
    "            events = pd.concat([events_dict[year][dkey] for dkey in DATA_KEYS])\n",
    "\n",
    "        bins = np.linspace(0, 250, 50)\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(24, 10))\n",
    "\n",
    "        for i, (jet, jlabel) in enumerate(\n",
    "            zip([\"bb\", \"tautau\"], [\"bb FatJet\", r\"$\\tau\\tau$ FatJet\"])\n",
    "        ):\n",
    "            ax = axs[i]\n",
    "            if key == \"hhbbtt\":\n",
    "                mask = taggers_dict[year][SIG_KEY][f\"{jet}_mask\"]\n",
    "            else:\n",
    "                mask = np.concatenate(\n",
    "                    [taggers_dict[year][dkey][f\"{jet}_mask\"] for dkey in DATA_KEYS], axis=0\n",
    "                )\n",
    "\n",
    "            for j, (mkey, mlabel) in enumerate(\n",
    "                zip(\n",
    "                    [\n",
    "                        \"ak8FatJetMsd\",\n",
    "                        \"ak8FatJetPNetmassLegacy\",\n",
    "                        \"ak8FatJetParTmassResApplied\",\n",
    "                        \"ak8FatJetParTmassVisApplied\",\n",
    "                    ],\n",
    "                    [\"SoftDrop\", \"PNetLegacy\", \"ParT Res\", \"ParT Vis\"],\n",
    "                )\n",
    "            ):\n",
    "                ax.hist(\n",
    "                    get_jet_vals(events[mkey], mask),\n",
    "                    bins=bins,\n",
    "                    histtype=\"step\",\n",
    "                    weights=events[\"finalWeight\"],\n",
    "                    label=mlabel,\n",
    "                    linewidth=2,\n",
    "                    color=plt.cm.tab10.colors[j],\n",
    "                )\n",
    "\n",
    "            ax.vlines(125, 0, ax.get_ylim()[1], linestyle=\"--\", color=\"k\", alpha=0.1)\n",
    "            ax.set_title(jlabel, fontsize=24)\n",
    "            ax.set_xlabel(\"Mass [GeV]\")\n",
    "            # rax.set_xlabel(\"Mass [GeV]\")\n",
    "            ax.set_ylabel(\"Events\")\n",
    "            ax.legend()\n",
    "            ax.set_ylim(0)\n",
    "            hep.cms.label(\n",
    "                ax=ax,\n",
    "                data=key == \"data\",\n",
    "                year=year,\n",
    "                com=\"13.6\",\n",
    "                fontsize=20,\n",
    "                lumi=f\"{hh_vars.LUMI[year] / 1000:.1f}\",\n",
    "            )\n",
    "\n",
    "        plt.savefig(plot_dir / f\"{key}_{year}_mass.pdf\", bbox_inches=\"tight\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut-and-count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbeff, tteff = 0.44, 0.36  # 0.44, 0.36 values determined by highest sig for 1 bkg event\n",
    "mbb1, mbb2 = 110.0, 160.0\n",
    "mbbw2 = (mbb2 - mbb1) / 2\n",
    "mtt1, mtt2 = 50, 1500\n",
    "\n",
    "# mbbk = \"PNetmassLegacy\"\n",
    "mbbk = \"ParTmassResApplied\"\n",
    "# mttk = \"PNetmassLegacy\"\n",
    "mttk = \"ParTmassResApplied\"\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    txbbcut = rocs[year][\"bb\"][\"XbbvsQCD\"][\"thresholds\"][\n",
    "        plotting._find_nearest(rocs[year][\"bb\"][\"XbbvsQCD\"][\"tpr\"], bbeff)\n",
    "    ]\n",
    "    txttcut = rocs[year][\"tautau\"][f\"{taukey}vsQCDTop\"][\"thresholds\"][\n",
    "        plotting._find_nearest(rocs[year][\"tautau\"][f\"{taukey}vsQCDTop\"][\"tpr\"], tteff)\n",
    "    ]\n",
    "    print(f\"TXbb cut, TXtt cut in {year}:\", txbbcut, txttcut)\n",
    "\n",
    "\n",
    "bg_combined = 0\n",
    "sig_combined = 0\n",
    "\n",
    "\n",
    "def compute_sig_bg(year, txbbcut, txttcut, mbb1, mbb2, mbbw2, mtt1, mtt2):\n",
    "    bg_yield = 0\n",
    "    sig_yield = 0\n",
    "\n",
    "    for key in [SIG_KEY] + DATA_KEYS:\n",
    "        txbbs = get_jet_vals(\n",
    "            taggers_dict[year][key][\"XbbvsQCD\"], taggers_dict[year][key][\"bb_mask\"]\n",
    "        )\n",
    "        txtts = get_jet_vals(\n",
    "            taggers_dict[year][key][f\"{taukey}vsQCDTop\"], taggers_dict[year][key][\"tautau_mask\"]\n",
    "        )\n",
    "        masstt = get_jet_vals(\n",
    "            events_dict[year][key][f\"ak8FatJet{mttk}\"], taggers_dict[year][key][\"tautau_mask\"]\n",
    "        )\n",
    "        massbb = get_jet_vals(\n",
    "            events_dict[year][key][f\"ak8FatJet{mbbk}\"], taggers_dict[year][key][\"bb_mask\"]\n",
    "        )\n",
    "        ptbb = get_jet_vals(\n",
    "            events_dict[year][key][\"ak8FatJetPt\"], taggers_dict[year][key][\"bb_mask\"]\n",
    "        )\n",
    "        # plt.hist(massbb, np.linspace(0, 200, 100), histtype=\"step\", label=key, weights=events_dict[key][\"finalWeight\"])\n",
    "\n",
    "        if key == SIG_KEY:\n",
    "            cut = (\n",
    "                (txbbs > txbbcut)\n",
    "                & (txtts > txttcut)\n",
    "                & (masstt > mtt1)\n",
    "                & (masstt < mtt2)\n",
    "                & (massbb > mbb1)\n",
    "                & (massbb < mbb2)\n",
    "                & (ptbb > 250)\n",
    "            )\n",
    "            sig_yield = np.sum(events_dict[year][key][\"finalWeight\"][cut])\n",
    "        else:\n",
    "            cut = (\n",
    "                (txbbs > txbbcut)\n",
    "                & (txtts > txttcut)\n",
    "                & (masstt > mtt1)\n",
    "                & (masstt < mtt2)\n",
    "                & (ptbb > 250)\n",
    "            )\n",
    "            msb1 = (massbb > (mbb1 - mbbw2)) & (massbb < mbb1)\n",
    "            msb2 = (massbb > mbb2) & (massbb < (mbb2 + mbbw2))\n",
    "            bg_yield += np.sum(events_dict[year][key][\"finalWeight\"][cut & msb1])\n",
    "            bg_yield += np.sum(events_dict[year][key][\"finalWeight\"][cut & msb2])\n",
    "    return sig_yield, bg_yield\n",
    "\n",
    "\n",
    "def study_yield():\n",
    "\n",
    "    bg_combined = 0\n",
    "    sig_combined = 0\n",
    "\n",
    "    for year in years:\n",
    "        print(\n",
    "            f\"\"\"\n",
    "          \n",
    "          \n",
    "        Yield study year {year}:\n",
    "        \n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "        sig_yield, bg_yield = compute_sig_bg(year, txbbcut, txttcut, mbb1, mbb2, mbbw2, mtt1, mtt2)\n",
    "        print(\"Sig yield\", sig_yield)\n",
    "        print(\"BG yield\", bg_yield)\n",
    "        print(\"limit\", 2 * np.sqrt(bg_yield) / sig_yield)\n",
    "        print(\n",
    "            \"limit scaled to 22-23 all channels\",\n",
    "            2\n",
    "            * np.sqrt(bg_yield)\n",
    "            / sig_yield\n",
    "            / np.sqrt(hh_vars.LUMI[\"2022-2023\"] / hh_vars.LUMI[year] * 3),\n",
    "        )\n",
    "        print(\n",
    "            \"limit scaled to 22-24 all channels\",\n",
    "            2\n",
    "            * np.sqrt(bg_yield)\n",
    "            / sig_yield\n",
    "            / np.sqrt((124000 + hh_vars.LUMI[\"2022-2023\"]) / hh_vars.LUMI[year] * 3),\n",
    "        )\n",
    "        print(\n",
    "            \"limit scaled to Run 3 all channels\",\n",
    "            2 * np.sqrt(bg_yield) / sig_yield / np.sqrt((360000) / hh_vars.LUMI[year] * 3),\n",
    "        )\n",
    "\n",
    "        bg_combined += bg_yield\n",
    "        sig_combined += sig_yield\n",
    "\n",
    "    return sig_combined, bg_combined\n",
    "\n",
    "\n",
    "sig_combined, bg_combined = study_yield()\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "          \n",
    "          \n",
    "        Yield study years combined {years}:\n",
    "          \n",
    "\n",
    "          \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"Sig yield\", sig_combined)\n",
    "print(\"BG yield\", bg_combined)\n",
    "print(\"limit\", 2 * np.sqrt(bg_combined) / sig_combined)\n",
    "print(\n",
    "    \"limit scaled to 22-23 all channels\",\n",
    "    2\n",
    "    * np.sqrt(bg_combined)\n",
    "    / sig_combined\n",
    "    / np.sqrt(hh_vars.LUMI[\"2022-2023\"] / np.sum([hh_vars.LUMI[year] for year in years]) * 3),\n",
    ")\n",
    "print(\n",
    "    \"limit scaled to 22-24 all channels\",\n",
    "    2\n",
    "    * np.sqrt(bg_combined)\n",
    "    / sig_combined\n",
    "    / np.sqrt(\n",
    "        (124000 + hh_vars.LUMI[\"2022-2023\"]) / np.sum([hh_vars.LUMI[year] for year in years]) * 3\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    \"limit scaled to Run 3 all channels\",\n",
    "    2\n",
    "    * np.sqrt(bg_combined)\n",
    "    / sig_combined\n",
    "    / np.sqrt((360000) / np.sum([hh_vars.LUMI[year] for year in years]) * 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Period (Electrons)**                        | **2022**  | **2022EE** | **Combined (2022, 2022EE)** |\n",
    "|-------------------------------------|----------:|----------:|---------------------------:|\n",
    "| **Sig yield**                       | 0.015     | 0.046     | 0.061                     |\n",
    "| **BG yield**                        | 2.000     | 7.000     | 9.000                     |\n",
    "| **limit**                           | 190.635   | 115.250   | 98.765                    |\n",
    "| **limit scaled to 22-23 channels**  | 39.654    | 43.576    | 42.621                    |\n",
    "| **limit scaled to 22-24 channels**  | 22.821    | 25.078    | 24.529                    |\n",
    "| **limit scaled to Run 3 channels**  | 16.378    | 17.997    | 17.603                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Period (Muons)**                        | **2022**  | **2022EE** | **Combined (2022, 2022EE)** |\n",
    "|-------------------------------------|---------:|----------:|---------------------------:|\n",
    "| **Sig yield**                       | 0.015    | 0.047     | 0.062                     |\n",
    "| **BG yield**                        | 0.000    | 3.000     | 3.000                     |\n",
    "| **limit**                           | 0.000    | 73.528    | 55.506                    |\n",
    "| **limit scaled to 22-23 channels**  | 0.000    | 27.801    | 23.953                    |\n",
    "| **limit scaled to 22-24 channels**  | 0.000    | 16.000    | 13.785                    |\n",
    "| **limit scaled to Run 3 channels**  | 0.000    | 11.482    | 9.893                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Period (Full hadronic)**                        | **2022**  | **2022EE** | **Combined (2022, 2022EE)** |\n",
    "|-------------------------------------|---------:|----------:|---------------------------:|\n",
    "| **Sig yield**                       | 0.032    | 0.104     | 0.136                     |\n",
    "| **BG yield**                        | 1.000    | 3.000     | 4.000                     |\n",
    "| **limit**                           | 62.243   | 33.457    | 29.483                    |\n",
    "| **limit scaled to 22-23 channels**  | 12.947   | 12.650    | 12.723                    |\n",
    "| **limit scaled to 22-24 channels**  | 7.451    | 7.280     | 7.322                     |\n",
    "| **limit scaled to Run 3 channels**  | 5.347    | 5.225     | 5.255                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
