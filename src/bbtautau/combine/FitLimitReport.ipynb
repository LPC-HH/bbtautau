{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Fit and Limit Analysis Report\n",
    "\n",
    "This notebook analyzes the results from HiggsCombine fits, extracting:\n",
    "- Asymptotic limits and their uncertainties\n",
    "- Fit convergence status\n",
    "- Nuisance parameter pulls and constraints\n",
    "- Summary statistics across multiple card directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "from pathlib import Path\n",
    "\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Set up plotting with CMS style\n",
    "plt.style.use(hep.style.CMS)\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams[\"font.size\"] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CARDS_BASE_DIR = \"/home/users/lumori/bbtautau/src/bbtautau/cards/25Dec27-ggf-only\"\n",
    "CHANNELS = [\"combined\", \"hh\", \"he\", \"hm\"]\n",
    "\n",
    "\n",
    "# Find all card directories with outputs\n",
    "def find_output_directories():\n",
    "    \"\"\"Find all directories containing analysis outputs\"\"\"\n",
    "    output_dirs = []\n",
    "\n",
    "    for root, dirs, files in os.walk(CARDS_BASE_DIR):\n",
    "        if \"outs\" in dirs:\n",
    "            outs_path = Path(root) / \"outs\"\n",
    "            if any(outs_path.glob(\"*.txt\")):\n",
    "                output_dirs.append(root)\n",
    "\n",
    "    return sorted(output_dirs)\n",
    "\n",
    "\n",
    "output_dirs = find_output_directories()\n",
    "print(f\"Found {len(output_dirs)} directories with outputs:\")\n",
    "for d in output_dirs:\n",
    "    print(f\"  - {Path(d).relative_to(CARDS_BASE_DIR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_asymptotic_limits(file_path):\n",
    "    \"\"\"Parse asymptotic limits from log file\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    if not Path(file_path).exists():\n",
    "        return results\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Look for expected limits pattern\n",
    "        patterns = {\n",
    "            \"expected_2.5\": r\"Expected\\s+2\\.5%:\\s*r\\s*<\\s*([0-9.]+)\",\n",
    "            \"expected_16.0\": r\"Expected\\s+16\\.0%:\\s*r\\s*<\\s*([0-9.]+)\",\n",
    "            \"expected_50.0\": r\"Expected\\s+50\\.0%:\\s*r\\s*<\\s*([0-9.]+)\",\n",
    "            \"expected_84.0\": r\"Expected\\s+84\\.0%:\\s*r\\s*<\\s*([0-9.]+)\",\n",
    "            \"expected_97.5\": r\"Expected\\s+97\\.5%:\\s*r\\s*<\\s*([0-9.]+)\",\n",
    "            \"observed\": r\"Observed\\s+Limit:\\s*r\\s*<\\s*([0-9.]+)\",\n",
    "        }\n",
    "\n",
    "        for key, pattern in patterns.items():\n",
    "            match = re.search(pattern, content, re.IGNORECASE)\n",
    "            if match:\n",
    "                results[key] = float(match.group(1))\n",
    "\n",
    "        # Check for convergence issues\n",
    "        convergence_issues = []\n",
    "        if \"Minimization did NOT converge\" in content:\n",
    "            convergence_issues.append(\"did_not_converge\")\n",
    "\n",
    "        results[\"convergence_issues\"] = convergence_issues\n",
    "        results[\"status\"] = \"success\" if not convergence_issues else \"issues\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {file_path}: {e}\")\n",
    "        results[\"status\"] = \"parse_error\"\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def parse_background_fit(file_path):\n",
    "    \"\"\"Parse background fit results\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    if not Path(file_path).exists():\n",
    "        return results\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Check fit status\n",
    "        if \"Minimization success!\" in content:\n",
    "            results[\"fit_converged\"] = True\n",
    "        elif \"Minimization did NOT converge\" in content:\n",
    "            results[\"fit_converged\"] = False\n",
    "        else:\n",
    "            results[\"fit_converged\"] = None\n",
    "\n",
    "        # Extract fit statistics\n",
    "        nll_match = re.search(r\"best fit NLL\\s*=\\s*([0-9.-]+)\", content)\n",
    "        if nll_match:\n",
    "            results[\"best_fit_nll\"] = float(nll_match.group(1))\n",
    "\n",
    "        # Count function calls\n",
    "        fcn_calls = len(re.findall(r\"FCN\", content))\n",
    "        results[\"function_calls\"] = fcn_calls\n",
    "\n",
    "        # Check for specific issues\n",
    "        issues = []\n",
    "        if \"Hesse matrix not pos-def\" in content:\n",
    "            issues.append(\"hesse_not_posdef\")\n",
    "        if \"MIGRAD FAILS\" in content:\n",
    "            issues.append(\"migrad_failed\")\n",
    "        if \"Covariance matrix\" in content and \"not available\" in content:\n",
    "            issues.append(\"no_covariance\")\n",
    "\n",
    "        results[\"fit_issues\"] = issues\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing background fit {file_path}: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Test parsing on first directory\n",
    "if output_dirs:\n",
    "    test_dir = Path(output_dirs[0]) / \"outs\"\n",
    "    print(f\"Testing parsing on: {test_dir}\")\n",
    "\n",
    "    # Look for limit files\n",
    "    limit_files = list(test_dir.glob(\"*AsymptoticLimits.txt\"))\n",
    "    if limit_files:\n",
    "        test_results = parse_asymptotic_limits(limit_files[0])\n",
    "        print(f\"Sample limit parsing: {test_results}\")\n",
    "\n",
    "    # Look for background fit files\n",
    "    bfit_files = list(test_dir.glob(\"*MultiDimFit.txt\"))\n",
    "    if bfit_files:\n",
    "        test_bfit = parse_background_fit(bfit_files[0])\n",
    "        print(f\"Sample background fit parsing: {test_bfit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal region labels: ggf, vbf, or allsigs (ggf+vbf combined)\n",
    "SIG_REGION_LABELS = [\"\", \"ggf\", \"vbf\", \"all\"]\n",
    "\n",
    "\n",
    "def collect_all_results():\n",
    "    \"\"\"Collect results from all output directories\"\"\"\n",
    "    all_results = []\n",
    "\n",
    "    for card_dir in output_dirs:\n",
    "        outs_dir = Path(card_dir) / \"outs\"\n",
    "        card_name = Path(card_dir).relative_to(CARDS_BASE_DIR)\n",
    "\n",
    "        print(f\"Processing: {card_name}\")\n",
    "\n",
    "        # Check for different channel and signal region results\n",
    "        for channel in CHANNELS:\n",
    "            for siglabel in SIG_REGION_LABELS:\n",
    "                # Build label: siglabel + channel\n",
    "                channellabel = \"\" if channel == \"combined\" else channel\n",
    "                label = f\"{siglabel}{channellabel}\"\n",
    "\n",
    "                result_entry = {\n",
    "                    \"card_directory\": str(card_name),\n",
    "                    \"channel\": channel,\n",
    "                    \"sig_region\": siglabel,\n",
    "                }\n",
    "\n",
    "                # Look for limits file\n",
    "                limit_file = outs_dir / f\"{label}AsymptoticLimits.txt\"\n",
    "                bfit_file = outs_dir / f\"{label}MultiDimFit.txt\"\n",
    "\n",
    "                # Parse limits\n",
    "                limit_results = parse_asymptotic_limits(limit_file)\n",
    "                result_entry.update(limit_results)\n",
    "\n",
    "                # Parse background fit\n",
    "                bfit_results = parse_background_fit(bfit_file)\n",
    "                result_entry.update(bfit_results)\n",
    "\n",
    "                # Only add if we found some results\n",
    "                if limit_results or bfit_results:\n",
    "                    all_results.append(result_entry)\n",
    "\n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "\n",
    "# Collect all results\n",
    "results_df = collect_all_results()\n",
    "print(f\"\\nCollected results from {len(results_df)} analyses\")\n",
    "print(f\"Columns: {list(results_df.columns)}\")\n",
    "print(f\"\\nFirst few entries:\")\n",
    "display(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=== ANALYSIS SUMMARY ===\")\n",
    "print(f\"Total analyses: {len(results_df)}\")\n",
    "print(f\"Card directories: {results_df['card_directory'].nunique()}\")\n",
    "print(f\"Channels analyzed: {sorted(results_df['channel'].unique())}\")\n",
    "\n",
    "# Status summary\n",
    "if \"status\" in results_df.columns:\n",
    "    print(\"\\n=== LIMIT CALCULATION STATUS ===\")\n",
    "    status_counts = results_df[\"status\"].value_counts()\n",
    "    for status, count in status_counts.items():\n",
    "        print(f\"{status}: {count}\")\n",
    "\n",
    "# Convergence summary\n",
    "if \"fit_converged\" in results_df.columns:\n",
    "    print(\"\\n=== BACKGROUND FIT CONVERGENCE ===\")\n",
    "    conv_counts = results_df[\"fit_converged\"].value_counts()\n",
    "    for conv, count in conv_counts.items():\n",
    "        print(f\"{conv}: {count}\")\n",
    "\n",
    "# Expected limits summary\n",
    "if \"expected_50.0\" in results_df.columns:\n",
    "    limits_summary = results_df.groupby(\"channel\")[\"expected_50.0\"].agg(\n",
    "        [\"count\", \"mean\", \"std\", \"min\", \"max\"]\n",
    "    )\n",
    "\n",
    "    # Clean up channel names and column names\n",
    "    channel_name_map = {\"combined\": \"Combined\", \"hh\": \"œÑ_h œÑ_h\", \"he\": \"œÑ_h e\", \"hm\": \"œÑ_h Œº\"}\n",
    "\n",
    "    limits_summary.index = [channel_name_map.get(idx, idx) for idx in limits_summary.index]\n",
    "    limits_summary.columns = [\"Count\", \"Mean\", \"Std Dev\", \"Min\", \"Max\"]\n",
    "\n",
    "    print(\"\\n=== EXPECTED LIMITS (50%) BY CHANNEL ===\")\n",
    "    display(limits_summary.round(2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Detailed Results Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate transposed tables for each channel\n",
    "print(\"=== DETAILED RESULTS BY CHANNEL ===\")\n",
    "\n",
    "# Get available columns\n",
    "limit_cols = [\"expected_2.5\", \"expected_16.0\", \"expected_50.0\", \"expected_84.0\", \"expected_97.5\"]\n",
    "available_limit_cols = [col for col in limit_cols if col in results_df.columns]\n",
    "\n",
    "status_cols = [\"status\", \"fit_converged\"]\n",
    "available_status_cols = [col for col in status_cols if col in results_df.columns]\n",
    "\n",
    "# Create table for each channel\n",
    "channels = sorted(results_df[\"channel\"].unique())\n",
    "\n",
    "# Define nice column names\n",
    "column_name_map = {\n",
    "    \"expected_2.5\": \"Expected -2œÉ\",\n",
    "    \"expected_16.0\": \"Expected -1œÉ\",\n",
    "    \"expected_50.0\": \"Expected Median\",\n",
    "    \"expected_84.0\": \"Expected +1œÉ\",\n",
    "    \"expected_97.5\": \"Expected +2œÉ\",\n",
    "    \"status\": \"Status\",\n",
    "    \"fit_converged\": \"Fit Converged\",\n",
    "}\n",
    "\n",
    "# Define nice channel names\n",
    "channel_name_map = {\"combined\": \"Combined\", \"hh\": \"œÑ_h œÑ_h\", \"he\": \"œÑ_h œÑ_e\", \"hm\": \"œÑ_h œÑ_Œº\"}\n",
    "\n",
    "for channel in channels:\n",
    "    channel_data = results_df[results_df[\"channel\"] == channel].copy()\n",
    "\n",
    "    if len(channel_data) > 0:\n",
    "        # Select columns for this channel (excluding 'channel' since it's the same for all rows)\n",
    "        summary_cols = [\"card_directory\"] + available_limit_cols + available_status_cols\n",
    "        summary_table = channel_data[summary_cols].copy()\n",
    "\n",
    "        # Format the table - round to 2 decimal places\n",
    "        for col in available_limit_cols:\n",
    "            if col in summary_table.columns:\n",
    "                summary_table[col] = summary_table[col].round(2)\n",
    "\n",
    "        # Clean up card_directory names (remove underscores, make prettier)\n",
    "        summary_table[\"card_directory\"] = (\n",
    "            summary_table[\"card_directory\"].str.replace(\"_\", \" \").str.title()\n",
    "        )\n",
    "\n",
    "        # Transpose the table: set card_directory as index, then transpose\n",
    "        transposed_table = summary_table.set_index(\"card_directory\").T\n",
    "\n",
    "        # Rename the index (row names) to be more readable\n",
    "        transposed_table.index = [\n",
    "            column_name_map.get(idx, idx.replace(\"_\", \" \").title())\n",
    "            for idx in transposed_table.index\n",
    "        ]\n",
    "        # Remove the index name to avoid showing \"card_directory\" in top left\n",
    "        # transposed_table.index.name = \"\"\n",
    "\n",
    "        channel_display_name = channel_name_map.get(channel, channel.upper())\n",
    "        print(f\"\\n=== {channel_display_name} Channel ===\")\n",
    "        display(transposed_table)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(hep.style.CMS)\n",
    "hep.style.use(\"CMS\")\n",
    "\n",
    "from boostedhh import hh_vars\n",
    "\n",
    "years = [\"2022\", \"2022EE\", \"2023\", \"2023BPix\"]\n",
    "\n",
    "# Plot expected limits comparison\n",
    "# Single horizontal summary: for each bmin show the four channels with median, 68% and 95% expected bands.\n",
    "if \"expected_50.0\" in results_df.columns and len(results_df) > 0:\n",
    "    required_cols = [\n",
    "        \"expected_2.5\",\n",
    "        \"expected_16.0\",\n",
    "        \"expected_50.0\",\n",
    "        \"expected_84.0\",\n",
    "        \"expected_97.5\",\n",
    "    ]\n",
    "    plot_df = results_df.copy()\n",
    "    plot_df = plot_df[plot_df[\"channel\"].isin(CHANNELS)]\n",
    "\n",
    "    # Keep only rows with full bands available\n",
    "    plot_df = plot_df.dropna(subset=[col for col in required_cols if col in plot_df.columns])\n",
    "\n",
    "    if len(plot_df) > 0:\n",
    "        bmins = sorted(plot_df[\"card_directory\"].unique())\n",
    "        channels = [ch for ch in CHANNELS if ch in plot_df[\"channel\"].unique()]\n",
    "\n",
    "        fig_height = 2 * len(bmins) + 2\n",
    "        fig, ax = plt.subplots(figsize=(18, fig_height))\n",
    "\n",
    "        base_y = np.arange(len(bmins))\n",
    "        bar_h = 0.18\n",
    "        offsets = np.linspace(-0.27, 0.27, len(channels)) if channels else np.array([0.0])\n",
    "        palette = [\"#1f77b4\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\"]\n",
    "\n",
    "        for i, ch in enumerate(channels):\n",
    "            ch_df = plot_df[plot_df[\"channel\"] == ch].set_index(\"card_directory\").reindex(bmins)\n",
    "            med = ch_df[\"expected_50.0\"].to_numpy()\n",
    "            low1 = ch_df[\"expected_16.0\"].to_numpy()\n",
    "            high1 = ch_df[\"expected_84.0\"].to_numpy()\n",
    "            low2 = ch_df[\"expected_2.5\"].to_numpy()\n",
    "            high2 = ch_df[\"expected_97.5\"].to_numpy()\n",
    "\n",
    "            mask = (\n",
    "                np.isfinite(med)\n",
    "                & np.isfinite(low1)\n",
    "                & np.isfinite(high1)\n",
    "                & np.isfinite(low2)\n",
    "                & np.isfinite(high2)\n",
    "            )\n",
    "            if not mask.any():\n",
    "                continue\n",
    "\n",
    "            y = base_y + offsets[i]\n",
    "            color = palette[i % len(palette)]\n",
    "\n",
    "            # 95% (2œÉ) band\n",
    "            ax.barh(\n",
    "                y[mask],\n",
    "                (high2 - low2)[mask],\n",
    "                left=low2[mask],\n",
    "                height=bar_h,\n",
    "                color=color,\n",
    "                alpha=0.25,\n",
    "                label=\"95% expected\" if i == 0 else None,\n",
    "            )\n",
    "            # 68% (1œÉ) band\n",
    "            ax.barh(\n",
    "                y[mask],\n",
    "                (high1 - low1)[mask],\n",
    "                left=low1[mask],\n",
    "                height=bar_h * 0.65,\n",
    "                color=color,\n",
    "                alpha=0.55,\n",
    "                label=\"68% expected\" if i == 0 else None,\n",
    "            )\n",
    "            # Median marker\n",
    "            ax.plot(med[mask], y[mask], \"o\", color=color, ms=6, label=\"Median\" if i == 0 else None)\n",
    "\n",
    "            # Channel legend handle (marker only) added once per channel\n",
    "            ax.plot([], [], marker=\"s\", color=color, ls=\"\", label=ch)\n",
    "\n",
    "        ax.set_yticks(base_y)\n",
    "        ax.set_yticklabels(bmins)\n",
    "        ax.set_xlabel(\"95% CL limit on $\\sigma / \\sigma_{SM}$\")\n",
    "        ax.set_ylabel(\"Experiment\")\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(True, axis=\"x\", ls=\":\", alpha=0.6)\n",
    "\n",
    "        ax.legend()\n",
    "\n",
    "        hep.cms.label(\n",
    "            ax=ax,\n",
    "            label=\"Work in Progress\",\n",
    "            data=True,\n",
    "            year=\"2022-23\",\n",
    "            com=\"13.6\",\n",
    "            fontsize=13,\n",
    "            lumi=f\"{np.sum([hh_vars.LUMI[year] for year in years]) / 1000:.1f}\",\n",
    "        )\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No limits with full bands to plot\")\n",
    "else:\n",
    "    print(\"Insufficient data for plotting\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Issues and Warnings Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify problematic analyses\n",
    "print(\"=== ISSUES AND WARNINGS REPORT ===\")\n",
    "\n",
    "# Convergence issues\n",
    "if \"fit_converged\" in results_df.columns:\n",
    "    non_converged = results_df[results_df[\"fit_converged\"] == False]\n",
    "    if len(non_converged) > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  NON-CONVERGED BACKGROUND FITS ({len(non_converged)})\")\n",
    "        for _, row in non_converged.iterrows():\n",
    "            print(f\"  - {row['card_directory']} / {row['channel']}\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ All background fits converged\")\n",
    "\n",
    "# Limit calculation issues\n",
    "if \"status\" in results_df.columns:\n",
    "    failed_limits = results_df[results_df[\"status\"] != \"success\"]\n",
    "    if len(failed_limits) > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  LIMIT CALCULATION ISSUES ({len(failed_limits)})\")\n",
    "        for _, row in failed_limits.iterrows():\n",
    "            issues = \", \".join(row.get(\"convergence_issues\", []))\n",
    "            print(f\"  - {row['card_directory']} / {row['channel']}: {row['status']} ({issues})\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ All limit calculations successful\")\n",
    "\n",
    "# Outlier limits (unusually high or low)\n",
    "if \"expected_50.0\" in results_df.columns:\n",
    "    valid_limits = results_df.dropna(subset=[\"expected_50.0\"])\n",
    "    if len(valid_limits) > 1:\n",
    "        Q1 = valid_limits[\"expected_50.0\"].quantile(0.25)\n",
    "        Q3 = valid_limits[\"expected_50.0\"].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        outliers = valid_limits[\n",
    "            (valid_limits[\"expected_50.0\"] < lower_bound)\n",
    "            | (valid_limits[\"expected_50.0\"] > upper_bound)\n",
    "        ]\n",
    "\n",
    "        if len(outliers) > 0:\n",
    "            print(f\"\\nüìä OUTLIER LIMITS ({len(outliers)})\")\n",
    "            print(f\"   Normal range: {lower_bound:.3f} - {upper_bound:.3f}\")\n",
    "            for _, row in outliers.iterrows():\n",
    "                print(f\"  - {row['card_directory']} / {row['channel']}: {row['expected_50.0']:.3f}\")\n",
    "        else:\n",
    "            print(\"\\n‚úÖ No outlier limits detected\")\n",
    "\n",
    "# Function call warnings\n",
    "if \"function_calls\" in results_df.columns:\n",
    "    high_calls = results_df[results_df[\"function_calls\"] > 10000]  # Arbitrary threshold\n",
    "    if len(high_calls) > 0:\n",
    "        print(f\"\\n‚è±Ô∏è  HIGH FUNCTION CALL COUNT ({len(high_calls)})\")\n",
    "        for _, row in high_calls.iterrows():\n",
    "            print(f\"  - {row['card_directory']} / {row['channel']}: {row['function_calls']} calls\")\n",
    "\n",
    "print(\"\\n=== END REPORT ===\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Export Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV for further analysis\n",
    "output_file = Path(CARDS_BASE_DIR) / \"analysis_results_summary.csv\"\n",
    "results_df.to_csv(output_file, index=False)\n",
    "print(f\"Results saved to: {output_file}\")\n",
    "\n",
    "# Create a summary report\n",
    "report_file = Path(CARDS_BASE_DIR) / \"analysis_report.txt\"\n",
    "with open(report_file, \"w\") as f:\n",
    "    f.write(\"HiggsCombine Analysis Report\\n\")\n",
    "    f.write(\"=\" * 30 + \"\\n\\n\")\n",
    "\n",
    "    f.write(f\"Generated: {pd.Timestamp.now()}\\n\\n\")\n",
    "\n",
    "    f.write(\"SUMMARY:\\n\")\n",
    "    f.write(f\"- Total analyses: {len(results_df)}\\n\")\n",
    "    f.write(f\"- Card directories: {results_df['card_directory'].nunique()}\\n\")\n",
    "    f.write(f\"- Channels: {', '.join(sorted(results_df['channel'].unique()))}\\n\\n\")\n",
    "\n",
    "    if \"expected_50.0\" in results_df.columns:\n",
    "        combined_limits = results_df[results_df[\"channel\"] == \"combined\"][\"expected_50.0\"].dropna()\n",
    "        if len(combined_limits) > 0:\n",
    "            f.write(\"COMBINED CHANNEL EXPECTED LIMITS:\\n\")\n",
    "            f.write(f\"- Best limit: {combined_limits.min():.3f}\\n\")\n",
    "            f.write(f\"- Median limit: {combined_limits.median():.3f}\\n\")\n",
    "            f.write(f\"- Worst limit: {combined_limits.max():.3f}\\n\\n\")\n",
    "\n",
    "    if \"fit_converged\" in results_df.columns:\n",
    "        conv_rate = results_df[\"fit_converged\"].sum() / len(results_df) * 100\n",
    "        f.write(f\"CONVERGENCE RATE: {conv_rate:.1f}%\\n\\n\")\n",
    "\n",
    "    f.write(\"DETAILED RESULTS: See analysis_results_summary.csv\\n\")\n",
    "\n",
    "print(f\"Summary report saved to: {report_file}\")\n",
    "print(\"\\nüìÅ Output files created:\")\n",
    "print(f\"  - {output_file.name}\")\n",
    "print(f\"  - {report_file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
